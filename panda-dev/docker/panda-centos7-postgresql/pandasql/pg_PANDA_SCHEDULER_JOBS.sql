-- Generated by Ora2Pg, the Oracle database Schema converter, version 21.1
-- Copyright 2000-2020 Gilles DAROLD. All rights reserved.
-- DATASOURCE: dbi:Oracle:INT8R

SET client_encoding TO 'UTF8';

SET search_path = doma_panda,public;
\set ON_ERROR_STOP ON

SET check_function_bodies = false;



CREATE OR REPLACE PROCEDURE doma_panda.add_dailypart (period_days bigint, n_table text, tablespace_name text) AS $body$
DECLARE

-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
i bigint;
j bigint;
days_plus bigint;
stmt varchar(1000);
top_value_long text;
top_value_string varchar(100);
part_boundary varchar(100);
part_name varchar(30);
fullq_name varchar(100);


BEGIN

 -- ver 1.1, last update 2th July 2013
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Create new partitions');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );


-- the DBMS_ASSERT.SQL_OBJECT_NAME function checks that the input string represents an existing object
-- The "ORA-44002: invalid object name" exception is raised when the input string does not match an existing object name
SELECT DBMS_ASSERT.SQL_OBJECT_NAME( sys_context('USERENV', 'CURRENT_SCHEMA') || '.' || UPPER(n_table) ) into STRICT fullq_name;



  i:= 0;
  days_plus := 0;

	-- get the top partition boundary
	SELECT high_value INTO STRICT top_value_long FROM (
	SELECT high_value FROM user_tab_partitions WHERE table_name = UPPER(n_table) ORDER BY PARTITION_POSITION desc
	) alias1 LIMIT 1;

	top_value_string := SUBSTR(top_value_long, 11, 19);

	FOR j in 1..period_days LOOP

 		part_boundary := to_char(TO_TIMESTAMP(top_value_string ,'YYYY-MM-DD HH24:MI:SS') + j, 'YYYY-MM-DD HH24:MI:SS');
 		part_boundary := 'TIMESTAMP '' ' || part_boundary || '''';

	      	days_plus := days_plus + 1;
		part_name :=  'PART_'|| n_table ||'_' || to_char(TO_TIMESTAMP(top_value_string ,'YYYY-MM-DD HH24:MI:SS') + days_plus, 'DDMMYYYY');

		stmt:= 'ALTER TABLE '|| n_table ||' ADD PARTITION '|| part_name || ' VALUES LESS THAN ('|| part_boundary ||') TABLESPACE ' || tablespace_name;

		--DBMS_OUTPUT.PUT_LINE(stmt);
		-- loop until succeeds
		LOOP
		   BEGIN
			-- create the new partition
			EXECUTE stmt;

			-- insert into the logging table , info on the newly created partition.
			INSERT INTO tablepart4copying(table_name, partition_name, copied_to_arch)
			VALUES (n_table, part_name, 'N');

		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN  DBMS_LOCK.sleep(1);
		   END;
		END LOOP;

	END LOOP;

	-- because of the last insert
	--COMMIT;


--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE add_dailypart (period_days bigint, n_table text, tablespace_name text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.add_dailypart (period_days bigint, n_table text, tablespace_name text) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.bulkcopy_panda_partitions (dest_schema text) AS $body$
DECLARE


stmt varchar(4000);
part_name varchar(30);
days_diff smallint;
n smallint;
valschema_name varchar(30);



BEGIN

-- Ver 2.11: 28th September 2020
-- Added column meanCoreCount to the JOBS tables
-- Ver 2.10: 28th April 2020
-- Added column job_label to the JOBS/TASK tables
-- Ver 2.9: 17th Mar 2019
-- Added column CONTAINER_NAME to the JOBS tables
-- Ver 2.8: 25th Nov 2019
-- Added column MEMORY_LEAK_X2 to the JOBS tables
-- Ver 2.7: 4th Nov 2019
-- Removed the insertion in the PANDAIDS_MODIFTIME table command
-- Ver 2.6: 10th April 2019
-- Added column MEMORY_LEAK to the JOBS tables
-- Ver 2.5: 20th March 2018
-- Added column DISKIO to the JOBS tables
-- Ver 2.4: 18th April 2017
-- Added column RESOURCE_TYPE to the JOBS tables
-- Ver 2.3: 2nd Feb 2017
-- Added columns totRCHAR, totWCHAR, totRBYTES, totWBYTES, rateRCHAR, rateWCHAR, rateRBYTES, rateWBYTES to the JOBS tables
-- Ver 2.2: 1st Nov 2016
-- Added column HS06 to the JOBS tables
-- Ver 2.1: 24th May 2016
-- Added two columns to the JOBS tables: FAILEDATTEMPT and HS06SEC
-- Update: 29th April 2016
-- Moved the insertion into the JOBSARCHIVED table at the end of the transaction because it was causing row lock contention when PanDA server
-- performs updates on the rows
-- Update: 4th Feb 2016
-- Added two columns to the JOBS tables: NUCLEUS and EVENTSERVICE
-- 18th June 2015: added 9 additional columns to the JOB tables (MAXRSS, MAXVMEM, MAXSWAP, MAXPSS, AVGRSS, AVGVMEM, AVGSWAP, AVGPSS, MAXWALLTIME)
-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Copy data from PanDA to PanDAARCH!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );

-- checks that the input string represents an existing schema name
-- "ORA-44001: invalid schema" exception is raised when the input string does not match an existing schema name.
SELECT DBMS_ASSERT.schema_name(UPPER(dest_schema)) INTO STRICT valschema_name;



SELECT (date_trunc('day', clock_timestamp() - MIN(to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY'))) )::numeric  INTO STRICT days_diff
FROM tablepart4copying WHERE copied_to_arch = 'N';

-- DBMS_OUTPUT.put_line(to_char(days_diff));
-- do NOT copy partitions that are from the current and last day
IF (days_diff < 1) THEN
return;
END IF;


-- for all partitions that have not been copied.
-- Usually it must be only one per day, but there might be cases when the copying has to compensate some lag of days
FOR n IN 1..days_diff LOOP


-- the METATABLE data
SELECT PARTITION_NAME into STRICT part_name FROM
tablepart4copying
WHERE table_name = 'METATABLE'
AND
to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY') =
(SELECT MIN(to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY')) FROM tablepart4copying WHERE copied_to_arch = 'N');


stmt:= 'INSERT /*+ append */ INTO '|| dest_schema ||'.metaTable_ARCH
(PANDAID,
MODIFICATIONTIME,
METADATA
)
SELECT
PANDAID,
MODIFICATIONTIME,
METADATA
FROM metaTable PARTITION('|| part_name ||')';

EXECUTE stmt;


-- put the logging info
UPDATE tablepart4copying SET copied_to_arch = 'Y' , copying_done_on = clock_timestamp() WHERE table_name = 'METATABLE' and partition_name = part_name AND copied_to_arch = 'N';


-- the PARAMSTABLE data
SELECT PARTITION_NAME into STRICT part_name
FROM tablepart4copying
WHERE table_name = 'JOBPARAMSTABLE'
AND
to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY') =
(SELECT MIN(to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY')) FROM tablepart4copying WHERE copied_to_arch = 'N');


stmt:= 'INSERT /*+ append */ INTO '|| dest_schema ||'.jobParamsTable_ARCH
(
PANDAID,
MODIFICATIONTIME,
JOBPARAMETERS
)
SELECT
PANDAID,
MODIFICATIONTIME,
JOBPARAMETERS
FROM jobParamsTable PARTITION('|| part_name ||')';

EXECUTE stmt;


-- put the logging info
UPDATE tablepart4copying SET copied_to_arch = 'Y' , copying_done_on = clock_timestamp() WHERE table_name = 'JOBPARAMSTABLE' and partition_name = part_name AND copied_to_arch = 'N';


-- The FILES table
SELECT PARTITION_NAME into STRICT part_name
FROM tablepart4copying
WHERE table_name = 'FILESTABLE4'
AND
to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY') =
(SELECT MIN(to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY')) FROM tablepart4copying WHERE copied_to_arch = 'N');


stmt:= 'INSERT /*+ append */ INTO '|| dest_schema ||'.filesTable_ARCH
(DESTINATIONSE,
FSIZE,
MD5SUM,
CHECKSUM,
ROW_ID,
PANDAID,
MODIFICATIONTIME,
GUID,
LFN,
"TYPE",
DATASET,
STATUS,
PRODDBLOCK,
PRODDBLOCKTOKEN,
DISPATCHDBLOCK,
DISPATCHDBLOCKTOKEN,
DESTINATIONDBLOCK,
DESTINATIONDBLOCKTOKEN,
SCOPE,
JEDITASKID,
DATASETID,
FILEID,
ATTEMPTNR
)
SELECT
DESTINATIONSE,
FSIZE,
MD5SUM,
CHECKSUM,
ROW_ID,
PANDAID,
MODIFICATIONTIME,
GUID,
LFN,
"TYPE",
DATASET,
STATUS,
PRODDBLOCK,
PRODDBLOCKTOKEN,
DISPATCHDBLOCK,
DISPATCHDBLOCKTOKEN,
DESTINATIONDBLOCK,
DESTINATIONDBLOCKTOKEN,
SCOPE,
JEDITASKID,
DATASETID,
FILEID,
ATTEMPTNR
FROM filesTable4 PARTITION('|| part_name ||')';


EXECUTE stmt;

-- put the logging info
UPDATE tablepart4copying SET copied_to_arch = 'Y' , copying_done_on = clock_timestamp() WHERE table_name = 'FILESTABLE4' and partition_name = part_name AND copied_to_arch = 'N';



-- the JOBSARCHIVED table
SELECT PARTITION_NAME into STRICT part_name FROM tablepart4copying
WHERE table_name = 'JOBSARCHIVED4'
AND
to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY') =
(SELECT MIN(to_DATE(SUBSTR(partition_name, -8), 'DDMMYYYY')) FROM tablepart4copying WHERE copied_to_arch = 'N');

	-- DBMS_OUTPUT.put_line(part_name);
stmt := 'INSERT /*+ append*/ INTO ' || dest_schema ||'.jobsArchived
(SPECIALHANDLING,
JOBSETID,
CORECOUNT,
BATCHID,
PARENTID,
MAXCPUCOUNT,
MAXCPUUNIT,
MAXDISKCOUNT,
MAXDISKUNIT,
IPCONNECTIVITY,
MINRAMCOUNT,
MINRAMUNIT,
STARTTIME,
ENDTIME,
CPUCONSUMPTIONTIME,
CPUCONSUMPTIONUNIT,
COMMANDTOPILOT,
TRANSEXITCODE,
PILOTERRORCODE,
PILOTERRORDIAG,
EXEERRORCODE,
EXEERRORDIAG,
SUPERRORCODE,
SUPERRORDIAG,
DDMERRORCODE,
DDMERRORDIAG,
BROKERAGEERRORCODE,
BROKERAGEERRORDIAG,
JOBDISPATCHERERRORCODE,
JOBDISPATCHERERRORDIAG,
TASKBUFFERERRORCODE,
TASKBUFFERERRORDIAG,
COMPUTINGSITE,
COMPUTINGELEMENT,
JOBPARAMETERS,
METADATA,
PRODDBLOCK,
DISPATCHDBLOCK,
DESTINATIONDBLOCK,
DESTINATIONSE,
NEVENTS,
GRID,
CLOUD,
CPUCONVERSION,
SOURCESITE,
DESTINATIONSITE,
TRANSFERTYPE,
TASKID,
CMTCONFIG,
STATECHANGETIME,
PRODDBUPDATETIME,
LOCKEDBY,
RELOCATIONFLAG,
JOBEXECUTIONID,
VO,
PILOTTIMING,
WORKINGGROUP,
PROCESSINGTYPE,
PRODUSERNAME,
NINPUTFILES,
COUNTRYGROUP,
PANDAID,
JOBDEFINITIONID,
SCHEDULERID,
PILOTID,
CREATIONTIME,
CREATIONHOST,
MODIFICATIONTIME,
MODIFICATIONHOST,
ATLASRELEASE,
TRANSFORMATION,
HOMEPACKAGE,
PRODSERIESLABEL,
PRODSOURCELABEL,
PRODUSERID,
ASSIGNEDPRIORITY,
CURRENTPRIORITY,
ATTEMPTNR,
MAXATTEMPT,
JOBSTATUS,
JOBNAME,
NINPUTDATAFILES,
INPUTFILETYPE,
INPUTFILEPROJECT,
INPUTFILEBYTES,
NOUTPUTDATAFILES,
OUTPUTFILEBYTES,
JOBMETRICS,
WORKQUEUE_ID,
JEDITASKID,
JOBSUBSTATUS,
ACTUALCORECOUNT,
REQID,
MAXRSS,
MAXVMEM,
MAXSWAP,
MAXPSS,
AVGRSS,
AVGVMEM,
AVGSWAP,
AVGPSS,
MAXWALLTIME,
NUCLEUS,
EVENTSERVICE,
FAILEDATTEMPT,
HS06SEC,
GSHARE,
HS06,
TOTRCHAR,
TOTWCHAR,
TOTRBYTES,
TOTWBYTES,
RATERCHAR,
RATEWCHAR,
RATERBYTES,
RATEWBYTES,
RESOURCE_TYPE,
DISKIO,
MEMORY_LEAK,
MEMORY_LEAK_X2,
CONTAINER_NAME,
JOB_LABEL,
MEANCORECOUNT
)
(SELECT
SPECIALHANDLING,
JOBSETID,
CORECOUNT,
BATCHID,
PARENTID,
MAXCPUCOUNT,
MAXCPUUNIT,
MAXDISKCOUNT,
MAXDISKUNIT,
IPCONNECTIVITY,
MINRAMCOUNT,
MINRAMUNIT,
STARTTIME,
ENDTIME,
CPUCONSUMPTIONTIME,
CPUCONSUMPTIONUNIT,
COMMANDTOPILOT,
TRANSEXITCODE,
PILOTERRORCODE,
PILOTERRORDIAG,
EXEERRORCODE,
EXEERRORDIAG,
SUPERRORCODE,
SUPERRORDIAG,
DDMERRORCODE,
DDMERRORDIAG,
BROKERAGEERRORCODE,
BROKERAGEERRORDIAG,
JOBDISPATCHERERRORCODE,
JOBDISPATCHERERRORDIAG,
TASKBUFFERERRORCODE,
TASKBUFFERERRORDIAG,
COMPUTINGSITE,
COMPUTINGELEMENT,
JOBPARAMETERS,
METADATA,
PRODDBLOCK,
DISPATCHDBLOCK,
DESTINATIONDBLOCK,
DESTINATIONSE,
NEVENTS,
GRID,
CLOUD,
CPUCONVERSION,
SOURCESITE,
DESTINATIONSITE,
TRANSFERTYPE,
TASKID,
CMTCONFIG,
STATECHANGETIME,
PRODDBUPDATETIME,
LOCKEDBY,
RELOCATIONFLAG,
JOBEXECUTIONID,
VO,
PILOTTIMING,
WORKINGGROUP,
PROCESSINGTYPE,
PRODUSERNAME,
NINPUTFILES,
COUNTRYGROUP,
PANDAID,
JOBDEFINITIONID,
SCHEDULERID,
PILOTID,
CREATIONTIME,
CREATIONHOST,
MODIFICATIONTIME,
MODIFICATIONHOST,
ATLASRELEASE,
TRANSFORMATION,
HOMEPACKAGE,
PRODSERIESLABEL,
PRODSOURCELABEL,
PRODUSERID,
ASSIGNEDPRIORITY,
CURRENTPRIORITY,
ATTEMPTNR,
MAXATTEMPT,
JOBSTATUS,
JOBNAME,
NINPUTDATAFILES,
INPUTFILETYPE,
INPUTFILEPROJECT,
INPUTFILEBYTES,
NOUTPUTDATAFILES,
OUTPUTFILEBYTES,
JOBMETRICS,
WORKQUEUE_ID,
JEDITASKID,
JOBSUBSTATUS,
ACTUALCORECOUNT,
REQID,
MAXRSS,
MAXVMEM,
MAXSWAP,
MAXPSS,
AVGRSS,
AVGVMEM,
AVGSWAP,
AVGPSS,
MAXWALLTIME,
NUCLEUS,
EVENTSERVICE,
FAILEDATTEMPT,
HS06SEC,
GSHARE,
HS06,
TOTRCHAR,
TOTWCHAR,
TOTRBYTES,
TOTWBYTES,
RATERCHAR,
RATEWCHAR,
RATERBYTES,
RATEWBYTES,
RESOURCE_TYPE,
DISKIO,
MEMORY_LEAK,
MEMORY_LEAK_X2,
CONTAINER_NAME,
JOB_LABEL,
MEANCORECOUNT
FROM jobsArchived4 PARTITION (' || part_name || ')
)';


EXECUTE stmt;


--DBMS_OUTPUT.put_line(stmt);
-- put the logging info
UPDATE tablepart4copying SET copied_to_arch = 'Y' , copying_done_on = clock_timestamp() WHERE table_name = 'JOBSARCHIVED4' and partition_name = part_name AND copied_to_arch = 'N';



-- 15th August 2019: might be NOT needed any more as SQL depending on it is not found(!)
-- 19th Feb 2013: Insert PANDAIDs and their MODIFICATIONTIMEs into the auxiliary IOT table PANDAIDS_MODIFTIME
-- in case of any errors like constraint violation, then the errors will be logged into the ERRLOG_PANDAIDS_MODIFTIME table
-- 4th Nov 2019: commented out as considered "not necessary in BigPanDAMon"
/*
stmt := 'INSERT INTO '|| dest_schema ||'.PANDAIDS_MODIFTIME
SELECT PANDAID, MODIFICATIONTIME
FROM jobsArchived4 PARTITION (' || part_name || ')
LOG ERRORS INTO '|| dest_schema || '.PANDAIDS_MODIFTIME_ERRLOG REJECT LIMIT UNLIMITED';

EXECUTE IMMEDIATE stmt;
*/
--COMMIT;

END LOOP;


-- commented out because otherwise the rollback is executed silently and the ORA error is not returned to the user
--EXCEPTION
-- WHEN OTHERS THEN
--	ROLLBACK;
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE bulkcopy_panda_partitions (dest_schema text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.bulkcopy_panda_partitions (dest_schema text) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.datasets_90days_sl_window (DAYS_OFFSET bigint default 93) AS $body$
DECLARE

-- Procedure for sustaining 90 days sliding window in the PANDA.DATASETS table which has automatic INTERVAL partitioning NUMTOYMINTERVAL(1,'MONTH')
-- 93 days to be more secure as some for some sequential months we have 31 days
-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_parts part_names;
messg varchar(10);

BEGIN

-- ver 1.2, last update 2th July 2013
-- Note: Oracle does NOT allow dropping of the last remaining non-interval partition (ORA-14758)! That is why is better to have INTERVAL = 'YES' condition in the WHERE clause
-- get the older than the last 4 partitions (months)
SELECT partition_name BULK COLLECT INTO STRICT coll_parts
FROM USER_TAB_PARTITIONS
WHERE table_name = 'DATASETS'
AND INTERVAL = 'YES' AND partition_position <= (SELECT MAX(partition_position) - 4 FROM USER_TAB_PARTITIONS
WHERE table_name = 'DATASETS' );

-- do NOT drop partitions that are within 3 months from now. In that case exit the procedure
IF (coll_parts.COUNT <= 0) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions with data older than ' || DAYS_OFFSET::varchar || ' days for drop!';
	-- this RAISE call is commented out as the procedure will be called from within a scheduler job monthly and would be not good to be shown error on the shifters page
	-- RAISE_APPLICATION_ERROR(-20101, stmt );
	return;
END IF;


-- Verification and partition drop part --
FOR j IN 1 .. coll_parts.COUNT LOOP

	-- for each older than the last 4 partitions check whether the MAX(modificationdate) is smaller than DAYS_OFFSET (default 93) days
	stmt := 'SELECT (CASE WHEN MAX(modificationdate) < (SYSDATE - ' || DAYS_OFFSET::varchar || ') THEN ''OK'' ELSE ''NOT OK'' END ) FROM DATASETS PARTITION ( ' || coll_parts(j) || ')';
	EXECUTE stmt INTO STRICT messg;

	IF (messg = 'OK') THEN
		stmt := 'ALTER TABLE DATASETS DROP PARTITION ' || coll_parts(j);

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;
	END IF;

END LOOP;

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE datasets_90days_sl_window (DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.datasets_90days_sl_window (DAYS_OFFSET bigint default 93) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.delete_jedi_events_proc () AS $body$
DECLARE

  rows_cnt bigint;
  taskid_cnt bigint;
  --row_sum number := 0;
  --part_cnt number := 1;
  p RECORD;

BEGIN
  EXECUTE 'alter session set ddl_lock_timeout=30';

  for p in (select PARTITION_NAME from user_tab_partitions where table_name = 'JEDI_EVENTS') loop

    EXECUTE 'SELECT COUNT(*) FROM doma_panda.JEDI_Events PARTITION ('||p.PARTITION_NAME||')' into STRICT rows_cnt;

    EXECUTE 'SELECT COUNT(*) 
                      FROM doma_panda.JEDI_Tasks t 
                      JOIN doma_panda.JEDI_Events PARTITION ('||p.PARTITION_NAME||') e 
                      ON (t.JEDITASKID = e.JEDITASKID)
                      WHERE t.STATUS IN (''done'', ''finished'', ''aborted'', ''failed'', ''broken'') 
                      AND t.MODIFICATIONTIME < sysdate - 90' into STRICT taskid_cnt;

    if (rows_cnt = taskid_cnt and rows_cnt <> 0) then
      --dbms_output.put_line('ALTER TABLE doma_panda.JEDI_Events DROP PARTITION '||p.PARTITION_NAME||' update global indexes;');
      EXECUTE 'ALTER TABLE doma_panda.JEDI_Events DROP PARTITION '||p.PARTITION_NAME;
      --dbms_output.put_line(part_cnt||' '||p.PARTITION_NAME||' >>> '||rows_cnt);
      --row_sum := row_sum + taskid_cnt;
      --part_cnt := part_cnt + 1;
    end if;

  end loop;
  --dbms_output.put_line(row_sum);
END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE delete_jedi_events_proc () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.delete_jedi_events_proc () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.do_grants (obj_type text, obj_name text, owner_name text) AS $body$
DECLARE

	
	
	privs varchar(100);
BEGIN

	 -- need to put " " around the object names, because some users create the objects with preserved character case.
	IF (obj_name NOT IN ('DO_GRANTS','GRANTS_UPDATE','CREATE_SYN4EXIST_OBJ') AND substr(obj_name,1,4)<>'BIN$' AND substr(obj_name,1,4)<>'SYS_') THEN

		IF obj_type IN ('TABLE') THEN
        	 	EXECUTE 'GRANT SELECT,INSERT,UPDATE,DELETE on "'||obj_name||'" to doma_panda_writerole';
		        EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_panda_readrole';
		elsif obj_type = 'SEQUENCE' THEN
	        	EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_panda_writerole';
		        EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_panda_readrole';
		elsif obj_type IN ('VIEW', 'MATERIALIZED VIEW') THEN
			privs := ' SELECT,INSERT,UPDATE,DELETE ';
			FOR i IN 1..2 LOOP /*if fails on the first loop with error 01720, then goes to the EXEPTION and changes the statement */
				BEGIN
					EXECUTE 'GRANT '|| privs ||' on "'|| obj_name||'" to doma_panda_writerole';
				        EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_panda_readrole';
					EXIT;
				EXCEPTION
					WHEN SQLSTATE '50002' THEN
						privs := ' SELECT ';
				END;
			END LOOP;
		elsif obj_type IN ('PROCEDURE', 'PACKAGE','FUNCTION', 'TYPE') AND obj_name <> 'CREATE_SYN' THEN
	         	EXECUTE 'GRANT EXECUTE on "'||obj_name||'" to doma_panda_writerole';
		        EXECUTE 'GRANT EXECUTE on "'||obj_name||'" to doma_panda_readrole';
		END IF;
	END IF;
END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE do_grants (obj_type text, obj_name text, owner_name text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.do_grants (obj_type text, obj_name text, owner_name text) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.grant_privs4exist_obj (owner_name text ) AS $body$
DECLARE

	
	
	privs varchar(100);
  rec RECORD;
BEGIN
 -- need to put " " around the object names, because some users create the objects with preserved character case.
	-- IMPORTANT - GRANT OBJECT PRIVILEGES FIRST TO THE TABLES
	FOR rec in (SELECT object_name as obj_name, object_type as obj_type FROM all_objects WHERE owner = 'doma_panda' and object_type = 'table' and substr(object_name,1,4)<>'bin$' and  substr(object_name,1,4)<>'sys_') loop
       	 	EXECUTE 'GRANT SELECT,INSERT,UPDATE,DELETE on "'||rec.obj_name||'" to doma_panda_writerole';
	        EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_panda_readrole';
	END LOOP;

	FOR rec in (SELECT object_name as obj_name, object_type as obj_type FROM all_objects WHERE owner = 'doma_panda' and object_type in ('view','sequence','procedure', 'package', 'function', 'materialized view', 'type' ) order by object_type desc ) loop

		IF rec.obj_name NOT IN ('DO_GRANTS','GRANTS_UPDATE','GRANT_PRIVS4EXIST_OBJ') THEN
			IF rec.obj_type IN ('VIEW', 'MATERIALIZED VIEW' ) THEN
				privs := ' SELECT,INSERT,UPDATE,DELETE ';
				FOR i IN 1..2 LOOP /*if fails on the first loop with error 01720, then goes to the EXEPTION and changes the statement */
					BEGIN
						EXECUTE 'GRANT '|| privs ||' on "'||rec.obj_name||'" to doma_panda_writerole';
					        EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_panda_readrole';
						EXIT;
					EXCEPTION
						WHEN SQLSTATE '50002' THEN
						privs := ' SELECT ';
					END;
				END LOOP;
			elsif rec.obj_type = 'SEQUENCE' THEN
	        		EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_panda_writerole';
			        EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_panda_readrole';
			elsif rec.obj_type IN ('PROCEDURE', 'PACKAGE','FUNCTION', 'TYPE') AND rec.obj_name <> 'CREATE_SYN' THEN
		         	EXECUTE 'GRANT EXECUTE on "'||rec.obj_name||'" to doma_panda_writerole';
			        EXECUTE 'GRANT EXECUTE on "'||rec.obj_name||'" to doma_panda_readrole';
			END IF;
		END IF;
	END LOOP;
END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE grant_privs4exist_obj (owner_name text ) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.grant_privs4exist_obj (owner_name text ) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.harvester_workers_sl_window (DAYS_OFFSET bigint default 60) AS $body$
DECLARE

-- Procedure for sustaining N days sliding window in the PANDA.HARVESTER_WORKERS table which has automatic INTERVAL partitioning NUMTOYMINTERVAL(1,'MONTH')
-- The default is keep data for at least the last recent 60 days
-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_parts part_names;
messg varchar(10);

BEGIN

-- ver 1.0, last update 10th April 2018
-- Note: Oracle does NOT allow dropping of the last remaining non-interval partition (ORA-14758)! That is why is better to have INTERVAL = 'YES' condition in the WHERE clause
-- get the older than the last 4 partitions (months)
SELECT partition_name BULK COLLECT INTO STRICT coll_parts
FROM USER_TAB_PARTITIONS
WHERE table_name = 'HARVESTER_WORKERS'
AND INTERVAL = 'YES' AND partition_position <= (SELECT MAX(partition_position) - 3 FROM USER_TAB_PARTITIONS WHERE table_name = 'HARVESTER_WORKERS' );

-- do NOT drop partitions that are within 2 months from now. In that case exit the procedure
IF (coll_parts.COUNT <= 0) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions with data older than ' || DAYS_OFFSET::varchar || ' days for drop!';
	-- this RAISE call is commented out as the procedure will be called from within a scheduler job monthly and would be not good to be shown error on the shifters page
	-- RAISE_APPLICATION_ERROR(-20101, stmt );
	return;
END IF;


-- Verification and partition drop part --
FOR j IN 1 .. coll_parts.COUNT LOOP

	-- for each older than the last 4 partitions check whether the MAX(modificationdate) is smaller than DAYS_OFFSET (default 93) days
	stmt := 'SELECT (CASE WHEN MAX(lastupdate) < (SYSDATE - ' || DAYS_OFFSET::varchar || ') THEN ''OK'' ELSE ''NOT OK'' END ) FROM doma_panda.HARVESTER_WORKERS PARTITION ( ' || coll_parts(j) || ')';
	EXECUTE stmt INTO STRICT messg;

	IF (messg = 'OK') THEN
		stmt := 'ALTER TABLE doma_panda.HARVESTER_WORKERS DROP PARTITION ' || coll_parts(j) || ' UPDATE GLOBAL INDEXES';

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;
	END IF;

END LOOP;

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE harvester_workers_sl_window (DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.harvester_workers_sl_window (DAYS_OFFSET bigint default 60) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.jedi_refr_mintaskids_bystatus () AS $body$
BEGIN

 -- ver 1.0, last update 2th July 2013
MERGE INTO JEDI_AUX_STATUS_MINTASKID tab
USING(SELECT status, MIN(jeditaskid) min_taskid from JEDI_TASKS WHERE status NOT IN ('broken', 'aborted', 'finished', 'failed') GROUP By status) sub
ON (tab.STATUS = sub.STATUS)
WHEN MATCHED THEN UPDATE SET
MIN_JEDITASKID = sub.min_taskid
WHEN NOT MATCHED THEN INSERT(tab.status, tab.min_jeditaskid)
VALUES (sub.status, sub.min_taskid);

--COMMIT;

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE jedi_refr_mintaskids_bystatus () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.jedi_refr_mintaskids_bystatus () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.jobs_statuslog_sl_window (DAYS_OFFSET bigint default 93) AS $body$
DECLARE

-- Procedure for sustaining 90 days sliding window in the PANDA.JOBS_STATUSLOG table which has automatic INTERVAL partitioning NUMTOYMINTERVAL(1,'MONTH')
-- 93 days to be more secure as some for some sequential months we have 31 days
-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_parts part_names;
messg varchar(10);

BEGIN

-- ver 1.3, last update 22th August 2017
-- ver 1.2, last update 30th Oct 2014
-- Note: Oracle does NOT allow dropping of the last remaining non-interval partition (ORA-14758)! That is why is better to have INTERVAL = 'YES' condition in the WHERE clause
-- get the older than 90 days 
SELECT partition_name BULK COLLECT INTO STRICT coll_parts
FROM USER_TAB_PARTITIONS
WHERE table_name = 'JOBS_STATUSLOG'
AND SEGMENT_CREATED = 'YES' AND INTERVAL <> 'NO' AND partition_position <= (SELECT MAX(partition_position) - DAYS_OFFSET FROM USER_TAB_PARTITIONS
WHERE table_name = 'JOBS_STATUSLOG' );

-- do NOT drop partitions that are within 3 months from now. In that case exit the procedure
IF (coll_parts.COUNT <= 0) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions with data older than ' || DAYS_OFFSET::varchar || ' days for drop!';
	-- this RAISE call is commented out as the procedure will be called from within a scheduler job monthly and would be not good to be shown error on the shifters page
	-- RAISE_APPLICATION_ERROR(-20101, stmt );
	return;
END IF;


-- Verification and partition drop part --
FOR j IN 1 .. coll_parts.COUNT LOOP

	-- for each older than the last 90 partitions check whether the MAX(modificationdate) is smaller than DAYS_OFFSET (default 93) days
	stmt := 'SELECT (CASE WHEN MAX(modificationtime) < (SYSDATE - ' || DAYS_OFFSET::varchar || ') THEN ''OK'' ELSE ''NOT OK'' END ) FROM JOBS_STATUSLOG PARTITION ( ' || coll_parts(j) || ')';
	EXECUTE stmt INTO STRICT messg;

	IF (messg = 'OK') THEN
		stmt := 'ALTER TABLE JOBS_STATUSLOG DROP PARTITION ' || coll_parts(j);

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;
	END IF;

END LOOP;

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE jobs_statuslog_sl_window (DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.jobs_statuslog_sl_window (DAYS_OFFSET bigint default 93) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.pandalog_sl_window (mytab_name text, DAYS_OFFSET bigint default 3) AS $body$
DECLARE

-- Procedure for sustaining DAYS_OFFSET days sliding window in the PANDALOG table which has automatic INTERVAL partitioning NUMTODSINTERVAL(1,'DAY')
-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_parts part_names;
messg varchar(10);
fullq_name varchar(100);

BEGIN

-- ver 1.2, last update 2th July 2013
-- Note: Oracle does NOT allow dropping of the last remaining non-interval partition (ORA-14758)! That is why is better to have INTERVAL = 'YES' condition in the WHERE clause
-- get the older than the last DAYS_OFFSET partitions (days)
-- the DBMS_ASSERT.SQL_OBJECT_NAME function checks that the input string represents an existing object
-- The "ORA-44002: invalid object name" exception is raised when the input string does not match an existing object name
SELECT DBMS_ASSERT.SQL_OBJECT_NAME( sys_context('USERENV', 'CURRENT_SCHEMA') || '.' || UPPER(mytab_name) ) into STRICT fullq_name;



SELECT partition_name BULK COLLECT INTO STRICT coll_parts
FROM USER_TAB_PARTITIONS
WHERE table_name = UPPER(mytab_name)
AND INTERVAL = 'YES' AND partition_position <= (SELECT MAX(partition_position) - DAYS_OFFSET FROM USER_TAB_PARTITIONS
WHERE table_name = UPPER(mytab_name) );

-- do NOT drop partitions that are within DAYS_OFFSET from now. In that case exit the procedure
IF (coll_parts.COUNT <= 0) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions with data older than ' || DAYS_OFFSET::varchar || ' days for drop!';
	-- this RAISE call is commented out as the procedure will be called from within a scheduler job monthly and would be not good to be shown error on the shifters page
	-- RAISE_APPLICATION_ERROR(-20101, stmt );
	return;
END IF;

-- Verification and partition drop part --
FOR j IN 1 .. coll_parts.COUNT LOOP

	-- for each older than the last DAYS_OFFSET partitions check whether the MAX(modificationdate) is smaller than DAYS_OFFSET days
	stmt := 'SELECT (CASE WHEN MAX(bintime) < (SYSDATE - ' || DAYS_OFFSET::varchar || ') THEN ''OK'' ELSE ''NOT OK'' END ) FROM ' ||UPPER(mytab_name)||' PARTITION ( ' || coll_parts(j) || ')';
	-- DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt INTO STRICT messg;

	IF (messg = 'OK') THEN
		stmt := 'ALTER TABLE '|| UPPER(mytab_name)||' DROP PARTITION ' || coll_parts(j);

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;
	END IF;

END LOOP;

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE pandalog_sl_window (mytab_name text, DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.pandalog_sl_window (mytab_name text, DAYS_OFFSET bigint default 3) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.panda_table_sl_window (mytab_name text, mytab_column text, DAYS_OFFSET bigint default 3) AS $body$
DECLARE

-- Procedure for sustaining DAYS_OFFSET days sliding window on a given table which has automatic INTERVAL partitioning NUMTODSINTERVAL(1,'DAY')
-- the DROP partition clause is with " UPDATE GLOBAL INDEXES" option
-- "mytab_name": name of the table on which will be enforced a sliding window policy
-- "mytab_column": a DATE or a TIMESTAMP column on which is based the RANGE (+ interval) partitioning
-- "days_offset": the number of most recent days(partitions) which have to stay in the table
-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_parts part_names;
messg varchar(10);
fullq_name varchar(100);

BEGIN

-- ver 1.0, last update 16th January 2015
-- Note: Oracle does NOT allow dropping of the last remaining non-interval partition (ORA-14758)! That is why is better to have INTERVAL = 'YES' condition in the WHERE clause
-- get the older than the last DAYS_OFFSET partitions (days)
-- the DBMS_ASSERT.SQL_OBJECT_NAME function checks that the input string represents an existing object
-- The "ORA-44002: invalid object name" exception is raised when the input string does not match an existing object name
SELECT DBMS_ASSERT.SQL_OBJECT_NAME( sys_context('USERENV', 'CURRENT_SCHEMA') || '.' || UPPER(mytab_name) ) into STRICT fullq_name;



SELECT partition_name BULK COLLECT INTO STRICT coll_parts
FROM USER_TAB_PARTITIONS
WHERE table_name = UPPER(mytab_name)
AND INTERVAL = 'YES' AND partition_position <= (SELECT MAX(partition_position) - DAYS_OFFSET FROM USER_TAB_PARTITIONS
WHERE table_name = UPPER(mytab_name) );

-- do NOT drop partitions that are within DAYS_OFFSET from now. In that case exit the procedure
IF (coll_parts.COUNT <= 0) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions with data older than ' || DAYS_OFFSET::varchar || ' days for drop!';
	-- this RAISE call is commented out as the procedure will be called from within a scheduler job monthly and would be not good to be shown error on the shifters page
	-- RAISE_APPLICATION_ERROR(-20101, stmt );
	return;
END IF;

-- Verification and partition drop part --
FOR j IN 1 .. coll_parts.COUNT LOOP

	-- for each older than the last DAYS_OFFSET partitions check whether the MAX(modificationdate) is smaller than DAYS_OFFSET days
	stmt := 'SELECT (CASE WHEN MAX('||mytab_column||') < (SYSDATE - ' || DAYS_OFFSET::varchar || ') THEN ''OK'' ELSE ''NOT OK'' END ) FROM ' ||UPPER(mytab_name)||' PARTITION ( ' || coll_parts(j) || ')';
	-- DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt INTO STRICT messg;

	IF (messg = 'OK') THEN
		stmt := 'ALTER TABLE '|| UPPER(mytab_name)||' DROP PARTITION ' || coll_parts(j) || ' UPDATE GLOBAL INDEXES';

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;
	END IF;

END LOOP;

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE panda_table_sl_window (mytab_name text, mytab_column text, DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.panda_table_sl_window (mytab_name text, mytab_column text, DAYS_OFFSET bigint default 3) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.rebuild_table_indices (m_owner text, m_table text, m_tbs_name text) AS $body$
DECLARE

stmt varchar(300);
TYPE indx_collection IS TABLE OF varchar(30) INDEX BY integer;
indx_list indx_collection;
fullq_name varchar(100);

BEGIN

-- ver. 1.2, last update 2th July 2013
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Rebuild indexes of table ' || UPPER(m_table)|| '.' || UPPER(m_table) );
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );

-- the DBMS_ASSERT.SQL_OBJECT_NAME function checks that the input string represents an existing object
-- The "ORA-44002: invalid object name" exception is raised when the input string does not match an existing object name
SELECT DBMS_ASSERT.SQL_OBJECT_NAME( UPPER(m_owner) || '.' || UPPER(m_table) ) into STRICT fullq_name;


SELECT index_name BULK COLLECT INTO STRICT indx_list
FROM all_indexes WHERE owner = UPPER(m_owner) AND table_name = UPPER(m_table) and index_type <> 'LOB';

	FOR j IN 1 .. indx_list.COUNT LOOP
		stmt := 'Alter index ' || UPPER(m_owner)|| '.' || UPPER(indx_list(j)) || ' rebuild ONLINE tablespace '
			|| DBMS_ASSERT.SIMPLE_SQL_NAME(UPPER(m_tbs_name));
		EXECUTE stmt;
	END LOOP;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);
END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE rebuild_table_indices (m_owner text, m_table text, m_tbs_name text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.rebuild_table_indices (m_owner text, m_table text, m_tbs_name text) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.tasks_statuslog_sl_window (DAYS_OFFSET bigint default 93) AS $body$
DECLARE

-- Procedure for sustaining 90 days sliding window in the PANDA.TASKS_STATUSLOG table which has automatic INTERVAL partitioning NUMTOYMINTERVAL(1,'DAY')
-- 93 days to be more secure as some for some sequential months we have 31 days
-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_parts part_names;
messg varchar(10);

BEGIN

-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Sliding window for TASKS_STATUSLOG');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );

-- ver 1.1, last update 11 March 2020, based on Gancho Dimitrov's JOBS_STATUSLOG_SL_WINDOW procedures
-- Note: Oracle does NOT allow dropping of the last remaining non-interval partition (ORA-14758)! That is why is better to have INTERVAL = 'YES' condition in the WHERE clause
-- get the older than 90 days 
SELECT partition_name BULK COLLECT INTO STRICT coll_parts
FROM USER_TAB_PARTITIONS
WHERE table_name = 'TASKS_STATUSLOG'
AND SEGMENT_CREATED = 'YES' AND INTERVAL <> 'NO' AND partition_position <= (SELECT MAX(partition_position) - DAYS_OFFSET FROM USER_TAB_PARTITIONS
WHERE table_name = 'TASKS_STATUSLOG' );

-- do NOT drop partitions that are within 3 months from now. In that case exit the procedure
IF (coll_parts.COUNT <= 0) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions with data older than ' || DAYS_OFFSET::varchar || ' days for drop!';
	-- this RAISE call is commented out as the procedure will be called from within a scheduler job monthly and would be not good to be shown error on the shifters page
	-- RAISE_APPLICATION_ERROR(-20101, stmt );
	return;
END IF;


-- Verification and partition drop part --
FOR j IN 1 .. coll_parts.COUNT LOOP

	-- for each older than the last 90 partitions check whether the MAX(modificationdate) is smaller than DAYS_OFFSET (default 93) days
	stmt := 'SELECT (CASE WHEN MAX(modificationtime) < (SYSDATE - ' || DAYS_OFFSET::varchar || ') THEN ''OK'' ELSE ''NOT OK'' END ) FROM TASKS_STATUSLOG PARTITION ( ' || coll_parts(j) || ')';
	EXECUTE stmt INTO STRICT messg;

	IF (messg = 'OK') THEN
		stmt := 'ALTER TABLE TASKS_STATUSLOG DROP PARTITION ' || coll_parts(j);

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;
	END IF;

END LOOP;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE tasks_statuslog_sl_window (DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.tasks_statuslog_sl_window (DAYS_OFFSET bigint default 93) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.update_jobsactive_stats () AS $body$
BEGIN

-- ver 1.2 , last modified on 2th July 2013
-- added VO and WORKQUEUE_ID columns
-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Aggregates data for the active jobs!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );


DELETE from mv_jobsactive4_stats;

INSERT INTO mv_jobsactive4_stats(CUR_DATE,
  CLOUD,
  COMPUTINGSITE,
  COUNTRYGROUP,
  WORKINGGROUP,
  RELOCATIONFLAG,
  JOBSTATUS,
  PROCESSINGTYPE,
  PRODSOURCELABEL,
  CURRENTPRIORITY,
  VO,
  WORKQUEUE_ID,
  NUM_OF_JOBS
  )
  SELECT
    clock_timestamp(),
    cloud,
    computingSite,
    countrygroup,
    workinggroup,
    relocationflag,
    jobStatus,
    processingType,
    prodSourceLabel,
    TRUNC(currentPriority, -1) AS currentPriority,
    VO,
    WORKQUEUE_ID,
    COUNT(*)  AS num_of_jobs
  FROM jobsActive4
  GROUP BY
    clock_timestamp(),
    cloud,
    computingSite,
    countrygroup,
    workinggroup,
    relocationflag,
    jobStatus,
    processingType,
    prodSourceLabel,
    TRUNC(currentPriority, -1),
    VO,
    WORKQUEUE_ID;
--COMMIT;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

end;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE update_jobsactive_stats () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.update_jobsactive_stats () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.update_jobsact_stats_by_gshare () AS $body$
BEGIN

-- 27th Nov 2020 , ver 1.4
-- 29th Jan 2018 , ver 1.3
-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Aggregates data by global share for the active jobs!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );

DELETE from doma_panda.JOBS_SHARE_STATS;

INSERT INTO doma_panda.JOBS_SHARE_STATS(TS, GSHARE, WORKQUEUE_ID, RESOURCE_TYPE,
                                          COMPUTINGSITE, JOBSTATUS,
                                          MAXPRIORITY, PRORATED_DISKIO_AVG, NJOBS, HS, VO)
SELECT clock_timestamp(), gshare, workqueue_id, ja4.resource_type, computingSite, jobStatus,
      MAX(currentPriority) AS maxPriority, AVG(diskIO/coalesce(ja4.coreCount, 1)) AS proratedDiskioAvg, COUNT(*) AS num_of_jobs,
      COUNT(*) * coalesce(ja4.coreCount, 1) * sc.corePower AS HS, VO
FROM doma_panda.jobsActive4 ja4, doma_pandameta.schedconfig sc
WHERE ja4.computingsite = sc.siteid
GROUP BY clock_timestamp(), gshare, workqueue_id, ja4.resource_type, computingSite, jobStatus, ja4.coreCount, sc.corePower, VO;


--COMMIT;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

end;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE update_jobsact_stats_by_gshare () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.update_jobsact_stats_by_gshare () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.update_jobsdef_stats_by_gshare () AS $body$
BEGIN

-- 27th Nov 2020 , ver 1.0
-- Based on UPDATE_JOBSACT_STATS_BY_GSHARE
-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Aggregates data by global share for the active jobs!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );


DELETE from doma_panda.JOBSDEFINED_SHARE_STATS;

INSERT INTO doma_panda.JOBSDEFINED_SHARE_STATS(TS, GSHARE, WORKQUEUE_ID, RESOURCE_TYPE,
                                          COMPUTINGSITE, JOBSTATUS,
                                          MAXPRIORITY, PRORATED_DISKIO_AVG, NJOBS, HS, VO)
SELECT clock_timestamp(), gshare, workqueue_id, ja4.resource_type, computingSite, jobStatus,
      MAX(currentPriority) AS maxPriority, AVG(diskIO/coalesce(ja4.coreCount, 1)) AS proratedDiskioAvg, COUNT(*) AS num_of_jobs,
      COUNT(*) * coalesce(ja4.coreCount, 1) * sc.corePower AS HS, VO
FROM doma_panda.jobsDefined4 ja4, doma_pandameta.schedconfig sc
WHERE ja4.computingsite = sc.siteid
GROUP BY clock_timestamp(), gshare, workqueue_id, ja4.resource_type, computingSite, jobStatus, ja4.coreCount, sc.corePower, VO;


--COMMIT;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

end;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE update_jobsdef_stats_by_gshare () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.update_jobsdef_stats_by_gshare () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.update_job_stats_hp () AS $body$
BEGIN

-- 30th Nov 2020 , ver 1.0
-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Counts jobs from all tables with max priority!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );


DELETE from doma_panda.JOB_STATS_HP;

INSERT INTO doma_panda.JOB_STATS_HP(TS, PRODSOURCELABEL, CLOUD, RESOURCE_TYPE, GSHARE, JOBSTATUS, WORKQUEUE_ID, VO, MAX_PRIORITY, MAX_PRIORITY_COUNT)
WITH ja4_stats AS (
    SELECT PRODSOURCELABEL, CLOUD, RESOURCE_TYPE, GSHARE, JOBSTATUS, WORKQUEUE_ID, VO, MAX(currentPriority) AS max_priority
    FROM doma_panda.jobsActive4 ja4
    WHERE PROCESSINGTYPE<>'pmerge'
    AND (coalesce(eventService::text, '') = '' OR eventService<>2)
    AND jobstatus = 'activated'
    GROUP BY PRODSOURCELABEL, CLOUD, RESOURCE_TYPE, GSHARE, JOBSTATUS, WORKQUEUE_ID, VO),

    jd4_stats AS (
    SELECT PRODSOURCELABEL, CLOUD, RESOURCE_TYPE, GSHARE, JOBSTATUS, WORKQUEUE_ID, VO, MAX(currentPriority) AS max_priority
    FROM doma_panda.jobsDefined4 ja4
    WHERE PROCESSINGTYPE<>'pmerge' 
    AND (coalesce(eventService::text, '') = '' OR eventService<>2)
    AND jobstatus IN ('assigned', 'defined')
    GROUP BY PRODSOURCELABEL, CLOUD, RESOURCE_TYPE, GSHARE, JOBSTATUS, WORKQUEUE_ID, VO
    )
SELECT clock_timestamp(), ja4.PRODSOURCELABEL, ja4.CLOUD, ja4.RESOURCE_TYPE, ja4.GSHARE, ja4.JOBSTATUS, ja4.WORKQUEUE_ID, ja4.VO, ja4_stats.max_priority, COUNT(*) AS max_priority_count
FROM doma_panda.jobsActive4 ja4, ja4_stats    
WHERE ja4.PRODSOURCELABEL = ja4_stats.PRODSOURCELABEL
AND ja4.PROCESSINGTYPE<>'pmerge' 
AND (coalesce(ja4.eventService::text, '') = '' OR ja4.eventService<>2)
AND ja4.CLOUD = ja4_stats.CLOUD
AND ja4.RESOURCE_TYPE = ja4_stats.RESOURCE_TYPE
AND ja4.GSHARE = ja4_stats.GSHARE
AND ja4.JOBSTATUS = ja4_stats.JOBSTATUS
AND ja4.WORKQUEUE_ID = ja4_stats.WORKQUEUE_ID
AND ja4.VO = ja4_stats.VO
AND ja4.currentpriority = ja4_stats.max_priority
AND coalesce(ja4.WORKQUEUE_ID, -1) = coalesce(ja4_stats.WORKQUEUE_ID, -1)
GROUP BY ja4.PRODSOURCELABEL, ja4.CLOUD, ja4.RESOURCE_TYPE, ja4.GSHARE, ja4.JOBSTATUS, ja4.WORKQUEUE_ID, ja4.VO, ja4_stats.max_priority

UNION

SELECT clock_timestamp(), jd4.PRODSOURCELABEL, jd4.CLOUD, jd4.RESOURCE_TYPE, jd4.GSHARE, jd4.JOBSTATUS, jd4.WORKQUEUE_ID, jd4.VO, jd4_stats.max_priority, COUNT(*) AS max_priority_count
FROM doma_panda.jobsDefined4 jd4, jd4_stats    
WHERE jd4.PRODSOURCELABEL = jd4_stats.PRODSOURCELABEL
AND jd4.PROCESSINGTYPE<>'pmerge' 
AND (coalesce(jd4.eventService::text, '') = '' OR jd4.eventService<>2)
AND jd4.CLOUD = jd4_stats.CLOUD
AND jd4.RESOURCE_TYPE = jd4_stats.RESOURCE_TYPE
AND jd4.GSHARE = jd4_stats.GSHARE
AND jd4.JOBSTATUS = jd4_stats.JOBSTATUS
AND jd4.WORKQUEUE_ID = jd4_stats.WORKQUEUE_ID
AND jd4.VO = jd4_stats.VO
AND jd4.currentpriority = jd4_stats.max_priority
AND coalesce(jd4.WORKQUEUE_ID, -1) = coalesce(jd4_stats.WORKQUEUE_ID, -1)
GROUP BY jd4.PRODSOURCELABEL, jd4.CLOUD, jd4.RESOURCE_TYPE, jd4.GSHARE, jd4.JOBSTATUS, jd4.WORKQUEUE_ID, jd4.VO, jd4_stats.max_priority;

--COMMIT;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

end;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE update_job_stats_hp () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.update_job_stats_hp () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.update_num_input_data_files () AS $body$
BEGIN

-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Calculates mean number of input files for the different types of jobs');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );

DELETE from doma_panda.typical_num_input;

INSERT INTO doma_panda.typical_num_input(agg_type, vo, agg_key, prodsourcelabel,
                                           processingtype, ninputdatafiles)
SELECT 'gshare' as agg_type, vo, gshare as agg_key, prodSourceLabel, processingType, PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY nInputDataFiles)
FROM doma_panda.jobsActive4
WHERE (nInputDataFiles IS NOT NULL AND nInputDataFiles::text <> '') 
    AND (vo IS NOT NULL AND vo::text <> '') 
    AND (prodsourcelabel IS NOT NULL AND prodsourcelabel::text <> '')
    AND (processingtype IS NOT NULL AND processingtype::text <> '')
    AND (gshare IS NOT NULL AND gshare::text <> '')
    AND workqueue_id IN (SELECT DISTINCT workqueue_id FROM doma_panda.jobsActive4
EXCEPT 
SELECT queue_id 
FROM doma_panda.jedi_work_queue WHERE queue_function = 'Resource')
GROUP BY vo, gshare, prodSourceLabel, processingType

UNION

SELECT 'workqueue' as agg_type, vo, workqueue_id::varchar as agg_key, prodSourceLabel, processingType, PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY nInputDataFiles)
FROM doma_panda.jobsActive4
WHERE (nInputDataFiles IS NOT NULL AND nInputDataFiles::text <> '') 
    AND (vo IS NOT NULL AND vo::text <> '') 
    AND (prodsourcelabel IS NOT NULL AND prodsourcelabel::text <> '')
    AND (processingtype IS NOT NULL AND processingtype::text <> '')
    AND (workqueue_id IS NOT NULL AND workqueue_id::text <> '')
    AND workqueue_id IN (SELECT queue_id FROM doma_panda.jedi_work_queue WHERE queue_function = 'Resource')
GROUP BY vo, WORKQUEUE_ID, prodSourceLabel, processingType;

--COMMIT;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

END;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE update_num_input_data_files () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.update_num_input_data_files () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.update_total_walltime () AS $body$
BEGIN

-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Calculates queued walltime');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );

DELETE from doma_panda.total_walltime_cache;

INSERT INTO doma_panda.total_walltime_cache(vo, agg_type, agg_key, prodsourcelabel, resource_type,
                                        total_walltime, n_has_value, n_no_value)
SELECT
   * 
FROM (
      SELECT
         vo, 'gshare' AS agg_type, gshare AS agg_key, prodsourcelabel, resource_type, 
         SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN maxwalltime ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 1 ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 0 ELSE 1 END)) 
      FROM
         doma_panda.jobsactive4 
      WHERE
         jobstatus IN ('activated', 'starting')
         AND workqueue_id IN (
            SELECT DISTINCT workqueue_id 
            FROM
               doma_panda.jobsactive4 EXCEPT 
               SELECT
                  queue_id 
               FROM
                  doma_panda.jedi_work_queue 
               WHERE
                  queue_function = 'Resource'
         )
      GROUP BY vo, gshare, prodsourcelabel, resource_type, agg_typegshare'
      
UNION

      SELECT
         vo, 'gshare' AS agg_type, gshare AS agg_key, prodsourcelabel, resource_type,
         SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN maxwalltime ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 1 ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 0 ELSE 1 END)) 
      FROM
         doma_panda.jobsdefined4 
      WHERE
         workqueue_id IN (
            SELECT DISTINCT workqueue_id 
            FROM
               doma_panda.jobsactive4 EXCEPT 
               SELECT
                  queue_id 
               FROM
                  doma_panda.jedi_work_queue 
               WHERE
                  queue_function = 'Resource'
         )
      GROUP BY vo, gshare, prodsourcelabel, resource_type, agg_typegshare'
   ) alias22

UNION

SELECT
   * 
FROM (
      SELECT
         vo, 'workqueue' AS agg_type, workqueue_id::varchar AS agg_key, prodsourcelabel, resource_type,
         SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN maxwalltime ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 1 ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 0 ELSE 1 END)) 
      FROM
         doma_panda.jobsactive4 
      WHERE
         jobstatus IN ('activated', 'starting')
         AND workqueue_id IN (
            SELECT
               queue_id 
            FROM
               doma_panda.jedi_work_queue 
            WHERE
               queue_function = 'Resource'
         )
      GROUP BY
         vo, workqueue_id::varchar, prodsourcelabel, resource_type, agg_typeworkqueue'
      
UNION

      SELECT
         vo, 'workqueue' AS agg_type, workqueue_id::varchar AS agg_key, prodsourcelabel, resource_type,
         SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN maxwalltime ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 1 ELSE 0 END)), SUM((CASE WHEN (maxwalltime IS NOT NULL AND maxwalltime::text <> '') THEN 0 ELSE 1 END)) 
      FROM
         doma_panda.jobsdefined4 
      WHERE
         workqueue_id IN (
            SELECT
               queue_id 
            FROM
               doma_panda.jedi_work_queue 
            WHERE
               queue_function = 'Resource'
         )
      GROUP BY
         vo, workqueue_id::varchar, prodsourcelabel, resource_type, agg_typeworkqueue'
   ) alias44
;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

end;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE update_total_walltime () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.update_total_walltime () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.update_ups_stats () AS $body$
DECLARE


binning bigint := 100;


BEGIN

-- 4th Dec 2020 , ver 1.0
-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Generates UPS statistics of activated jobs!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );


DELETE from doma_panda.UPS_STATS;

INSERT INTO doma_panda.UPS_STATS(TS, RESOURCE_TYPE, GSHARE, COMPUTINGSITE, JOBSTATUS, VO, CURRENT_PRIORITY_BINNED, CURRENT_PRIORITY_COUNT)
SELECT clock_timestamp(), resource_type, gshare, computingsite, jobstatus, vo, floor(currentpriority/binning)*binning, count(*) FROM doma_panda.jobsactive4
GROUP BY clock_timestamp(), computingsite, gshare, resource_type, jobstatus, vo, floor(currentpriority/binning);

--COMMIT;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

end;
$body$
LANGUAGE PLPGSQL
SECURITY DEFINER
;
ALTER PROCEDURE update_ups_stats () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.update_ups_stats () FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.verif_drop_copiedpandapart (arch_schema text, DAYS_OFFSET bigint default 2) AS $body$
DECLARE


-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
num_part bigint;
TYPE tab_names IS TABLE OF varchar(30) INDEX BY integer;
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_tables tab_names;
coll_parts part_names;
jobs_diff bigint;
valschema_name varchar(30);
BEGIN

-- ver 1.5, last update 2th July 2013
-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Verify data copying and remove partitions if the all data has been copied!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );


-- checks that the input string represents an existing schema name
-- "ORA-44001: invalid schema" exception is raised when the input string does not match an existing schema name.
SELECT DBMS_ASSERT.schema_name(UPPER(arch_schema)) INTO STRICT valschema_name;


SELECT COUNT(*) INTO STRICT num_part
FROM tablepart4copying
WHERE
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM tablepart4copying WHERE copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND (date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on)) >= DAYS_OFFSET;


-- do NOT drop partitions that are within 3 days from now. In that case exit the procedure
-- the number is 1 because minimum 1 partitions have to be dropped. In normal operation have to be 4 partitions, but I put 1 to foresee cases
-- where DB instance crashes and not all partitions could have been dropped
IF (num_part < 1) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions older than ' || DAYS_OFFSET || ' for drop!';
	RAISE EXCEPTION '%', stmt  USING ERRCODE = '45101';
	return;
END IF;


-- get the oldest partitions with conditions to be with offset of DAYS_OFFSET days from now
/*
SELECT table_name, partition_name BULK COLLECT INTO
coll_tables, coll_parts
FROM tablepart4copying
WHERE
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM tablepart4copying WHERE copied_to_arch = 'Y' AND deleted_on is NULL
)
AND deleted_on is NULL
AND ( TRUNC(sysdate) - TRUNC(copying_done_on) ) >= DAYS_OFFSET;
*/
-- 13th Feb 2012
-- new query with UNION as FILESTABLE4 table needs to have sliding window of 30 days (DAYS_OFFSET+28)
-- Note:
-- If data of several partitions have been copied at the same date for compensating some backlog, then in DAYS_OFFSET
-- they will be all dropped by this procedure with the logic encoded in this query - this is expected behaviour
SELECT table_name, partition_name BULK COLLECT INTO STRICT
coll_tables, coll_parts
FROM
(
SELECT table_name, partition_name
FROM tablepart4copying
WHERE
table_name <> 'FILESTABLE4'
AND
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM tablepart4copying WHERE table_name <> 'FILESTABLE4' AND copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND ( date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on) ) >= DAYS_OFFSET


UNION


SELECT table_name, partition_name
FROM tablepart4copying
WHERE
table_name = 'FILESTABLE4'
AND
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM tablepart4copying WHERE table_name = 'FILESTABLE4' AND copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND ( date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on) ) >= (DAYS_OFFSET+28)
) alias21;



-- Verification part --
-- Checks that the PANDAIDs of the partitions that need to be dropped are present (have been copied) to the corresponding ARCH tables
-- check for PANDAID set differences in the JOBSARCHIVED4
IF ( coll_tables.COUNT > 0 AND coll_tables.COUNT = coll_parts.COUNT ) THEN

	FOR j IN 1 .. coll_tables.COUNT LOOP

		IF coll_tables(j) = 'JOBSARCHIVED4' THEN
			jobs_diff := -1;

			-- with FULL table (actually single PARTITION) scan hint
			-- The cardinality hint is needed as sometimes for the partitions in question Oracle stats are missing !!!
			stmt :=	'SELECT /*+ CARDINALITY(tab 1000000) index_ffs(tab(PANDAID)) */ COUNT(pandaid)
			from JOBSARCHIVED4 PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT /*+ FULL(subt) CARDINALITY(subt 3000000) */ 1 FROM '|| arch_schema ||'.JOBSARCHIVED subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;


			IF (jobs_diff = 0)  THEN
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);										--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table JOBSARCHIVED4' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'JOBPARAMSTABLE' THEN
			jobs_diff := -1;

			stmt :=	'SELECT
				COUNT(pandaid)
				FROM JOBPARAMSTABLE PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT 1 FROM '|| arch_schema ||'.JOBPARAMSTABLE_ARCH subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;


			IF (jobs_diff = 0)  THEN
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
				--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table JOBPARAMSTABLE' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'METATABLE' THEN
			jobs_diff := -1;

			stmt :=	'SELECT
				COUNT(pandaid)
				FROM METATABLE PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT 1 FROM '|| arch_schema ||'.METATABLE_ARCH subt
			where PANDAID = tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;

			IF (jobs_diff = 0)  THEN
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);										--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table METATABLE' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'FILESTABLE4' THEN
			jobs_diff := -1;

			stmt:='SELECT
				COUNT(row_id)
				FROM filestable4 PARTITION('|| coll_parts(j) ||') tab
			WHERE NOT EXISTS (SELECT 1 FROM '|| arch_schema ||'.FILESTABLE_ARCH subt
			WHERE ROW_ID = tab.ROW_ID AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)
			AND MODIFICATIONTIME < TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;


			IF (jobs_diff = 0)  THEN
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);										--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table FILESTABLE4' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;
	END LOOP;
END IF;



-- end of the verification part --
IF ( coll_tables.COUNT > 0 AND coll_tables.COUNT = coll_parts.COUNT ) THEN

	FOR j IN 1 .. coll_tables.COUNT LOOP

		stmt := 'ALTER TABLE '|| coll_tables(j) || ' DROP PARTITION ' || coll_parts(j);

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;

			-- add info into the logging table 'tablepart4copying'
			UPDATE tablepart4copying SET deleted_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			--COMMIT;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;

	END LOOP;

	-- the commit is moved within the above loop
	-- --COMMIT;
END IF;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE verif_drop_copiedpandapart (arch_schema text, DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.verif_drop_copiedpandapart (arch_schema text, DAYS_OFFSET bigint default 2) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.verif_drop_copiedpandapart_v2 (DAYS_OFFSET bigint default 2) AS $body$
DECLARE


-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
num_part bigint;
TYPE tab_names IS TABLE OF varchar(30) INDEX BY integer;
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_tables tab_names;
coll_parts part_names;
jobs_diff bigint;
BEGIN

SELECT COUNT(*) INTO STRICT num_part
FROM doma_panda.tablepart4copying
WHERE
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM doma_panda.tablepart4copying WHERE copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND (date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on)) >= DAYS_OFFSET;


-- do NOT drop partitions that are within 3 days from now. In that case exit the procedure
-- the number is 1 because minimum 1 partitions have to be dropped. In normal operation have to be 4 partitions, but I put 1 to foresee cases
-- where DB instance crashes and not all partitions could have been dropped
IF (num_part < 1) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions older than ' || DAYS_OFFSET || ' for drop!';
	RAISE EXCEPTION '%', stmt  USING ERRCODE = '45101';
	return;
END IF;


-- get the oldest partitions with conditions to be with offset of DAYS_OFFSET days from now
SELECT table_name, partition_name BULK COLLECT INTO STRICT
coll_tables, coll_parts
FROM doma_panda.tablepart4copying
WHERE
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM doma_panda.tablepart4copying WHERE copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND ( date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on) ) >= DAYS_OFFSET;


-- Verification part --
-- Checks that the PANDAIDs of the partitions that need to be dropped are present (have been copied) to the corresponding ARCH tables
-- check for PANDAID set differences in the JOBSARCHIVED4
IF ( coll_tables.COUNT > 0 AND coll_tables.COUNT = coll_parts.COUNT ) THEN

	FOR j IN 1 .. coll_tables.COUNT LOOP

		IF coll_tables(j) = 'JOBSARCHIVED4' THEN
			jobs_diff := -1;

			-- with FULL table (actually single PARTITION) scan hint
			-- The cardinality hint is needed as sometimes for the partitions in question Oracle stats are missing !!!
			stmt :=	'SELECT /*+ CARDINALITY(tab 500000) index_ffs(tab(PANDAID)) */ COUNT(pandaid)
			from doma_panda.JOBSARCHIVED4 PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT /*+ FULL(subt) CARDINALITY(subt 2000000) */ 1 FROM doma_pandaarch.JOBSARCHIVED subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;

			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);							--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table JOBSARCHIVED4' USING ERRCODE = '45101';
				RETURN;
			END IF;
		END IF;

		IF coll_tables(j) = 'JOBPARAMSTABLE' THEN
			jobs_diff := -1;

			-- The cardinality hint is needed as sometimes for the partitions in question Oracle stats are missing !!!
			-- With INDEX_JOIN hint (Oracle does a hash join on the two indexes without the need to go to the table itself )
			stmt :=	'SELECT
				/*+
				      USE_HASH(@"SEL$5DA710D3" "SUBT"@"SEL$2")
				      LEADING(@"SEL$5DA710D3" "TAB"@"SEL$1" "SUBT"@"SEL$2")
				      INDEX_JOIN(@"SEL$5DA710D3" "SUBT"@"SEL$2" ("JOBPARAMSTABLE_ARCH"."MODIFICATIONTIME") ("JOBPARAMSTABLE_ARCH"."PANDAID"))
				      INDEX_FFS(@"SEL$5DA710D3" "TAB"@"SEL$1" ("JOBPARAMSTABLE"."PANDAID" "JOBPARAMSTABLE"."MODIFICATIONTIME"))
				      OUTLINE(@"SEL$2")
				      OUTLINE(@"SEL$1")
				      UNNEST(@"SEL$2")
				      OUTLINE(@"SEL$5DA710D3")
				      UNNEST(@"SEL$2")
				      OUTLINE_LEAF(@"SEL$5DA710D3")
				      OUTLINE_LEAF(@"SEL$6E51D5DC")
				*/				COUNT(pandaid)
				FROM doma_panda.JOBPARAMSTABLE PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT 1 FROM doma_pandaarch.JOBPARAMSTABLE_ARCH subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;

			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);						--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table JOBPARAMSTABLE' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'METATABLE' THEN
			jobs_diff := -1;

			-- The cardinality hint is needed as sometimes for the partitions in question Oracle stats are missing !!!
			-- With INDEX_JOIN hint (Oracle does a hash join on the two indexes without the need to go to the table itself )
			stmt :=	'SELECT
					/*+
					USE_HASH(@"SEL$5DA710D3" "SUBT"@"SEL$2")
					LEADING(@"SEL$5DA710D3" "TAB"@"SEL$1" "SUBT"@"SEL$2")
     					INDEX_JOIN(@"SEL$5DA710D3" "SUBT"@"SEL$2" ("METATABLE_ARCH"."MODIFICATIONTIME") ("METATABLE_ARCH"."PANDAID"))
     					INDEX_FFS(@"SEL$5DA710D3" "TAB"@"SEL$1" ("METATABLE"."PANDAID" "METATABLE"."MODIFICATIONTIME"))
	     				OUTLINE(@"SEL$2")
     					OUTLINE(@"SEL$1")
     					UNNEST(@"SEL$2")
     					OUTLINE(@"SEL$5DA710D3")
     					UNNEST(@"SEL$2")
     					OUTLINE_LEAF(@"SEL$5DA710D3")
     					OUTLINE_LEAF(@"SEL$6E51D5DC")
					*/				COUNT(pandaid)
				FROM doma_panda.METATABLE PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT 1 FROM doma_pandaarch.METATABLE_ARCH subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;

			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);							--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table METATABLE' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'FILESTABLE4' THEN
			jobs_diff := -1;

			-- The cardinality hint is needed as sometimes for the partitions in question Oracle stats are missing !!!
			-- With INDEX_JOIN hint (Oracle does a hash join on the two indexes without the need to go to the table itself )
			stmt:='SELECT
				/*+
				      USE_HASH(@"SEL$5DA710D3" "SUBT"@"SEL$2")
				      LEADING(@"SEL$5DA710D3" "TAB"@"SEL$1" "SUBT"@"SEL$2")
				      INDEX_JOIN(@"SEL$5DA710D3" "SUBT"@"SEL$2" ("FILESTABLE_ARCH"."MODIFICATIONTIME") ("FILESTABLE_ARCH"."ROW_ID"))
				      INDEX_FFS(@"SEL$5DA710D3" "TAB"@"SEL$1" ("FILESTABLE4"."ROW_ID" "FILESTABLE4"."MODIFICATIONTIME"))
				      OUTLINE(@"SEL$2")
				      OUTLINE(@"SEL$1")
				      UNNEST(@"SEL$2")
				      OUTLINE(@"SEL$5DA710D3")
				      UNNEST(@"SEL$2")
				      OUTLINE_LEAF(@"SEL$5DA710D3")
				      OUTLINE_LEAF(@"SEL$6E51D5DC")
				 */				COUNT(row_id)
				FROM doma_panda.filestable4 PARTITION('|| coll_parts(j) ||') tab
			WHERE NOT EXISTS (SELECT 1 FROM doma_pandaarch.FILESTABLE_ARCH subt
			WHERE ROW_ID = tab.ROW_ID AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)
			AND MODIFICATIONTIME < TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;


			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);							--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table FILESTABLE4' USING ERRCODE = '45101';
				RETURN;
			END IF;
		END IF;
	END LOOP;
END IF;


-- end of the verification part --
IF ( coll_tables.COUNT > 0 AND coll_tables.COUNT = coll_parts.COUNT ) THEN

	FOR j IN 1 .. coll_tables.COUNT LOOP

		stmt := 'ALTER TABLE '|| coll_tables(j) || ' DROP PARTITION ' || coll_parts(j);

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;

			-- add info into the logging table 'tablepart4copying'
			UPDATE doma_panda.tablepart4copying SET deleted_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			--COMMIT;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;

	END LOOP;

	-- the commit is moved within the above loop
	-- --COMMIT;
END IF;

END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE verif_drop_copiedpandapart_v2 (DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.verif_drop_copiedpandapart_v2 (DAYS_OFFSET bigint default 2) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_panda.verif_drop_copiedpandapart_v3 (DAYS_OFFSET bigint default 2) AS $body$
DECLARE


-- 7th Dec 2011, the SQL statements are without hints are I rely on another SCHEDULER job that collects stats beforehand on partition level
-- define exception handling for the "ORA-00054: resource busy and acquire with NOWAIT specified" error
stmt varchar(4000);
num_part bigint;
TYPE tab_names IS TABLE OF varchar(30) INDEX BY integer;
TYPE part_names IS TABLE OF varchar(30) INDEX BY integer;
coll_tables tab_names;
coll_parts part_names;
jobs_diff bigint;
BEGIN

-- to easy identify the session and better view on resource usage by setting a dedicated module for the PanDA jobs
--DBMS_APPLICATION_INFO.SET_MODULE( module_name => 'PanDA scheduler job', action_name => 'Verify data copying and remove partitions if the all data has been copied!');
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => sys_context('userenv', 'host') || ' ( ' || sys_context('userenv', 'ip_address') || ' )' );


SELECT COUNT(*) INTO STRICT num_part
FROM doma_panda.tablepart4copying
WHERE
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM doma_panda.tablepart4copying WHERE copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND (date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on)) >= DAYS_OFFSET;


-- do NOT drop partitions that are within 3 days from now. In that case exit the procedure
-- the number is 1 because minimum 1 partitions have to be dropped. In normal operation have to be 4 partitions, but I put 1 to foresee cases
-- where DB instance crashes and not all partitions could have been dropped
IF (num_part < 1) THEN
	stmt:= 'USER DEFINED INFO: There are NOT partitions older than ' || DAYS_OFFSET || ' for drop!';
	RAISE EXCEPTION '%', stmt  USING ERRCODE = '45101';
	return;
END IF;


-- get the oldest partitions with conditions to be with offset of DAYS_OFFSET days from now
/*
SELECT table_name, partition_name BULK COLLECT INTO
coll_tables, coll_parts
FROM doma_panda.tablepart4copying
WHERE
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM doma_panda.tablepart4copying WHERE copied_to_arch = 'Y' AND deleted_on is NULL
)
AND deleted_on is NULL
AND ( TRUNC(sysdate) - TRUNC(copying_done_on) ) >= DAYS_OFFSET;
*/
-- 13th Feb 2012
-- new query with UNION as FILESTABLE4 table needs to have sliding window of 30 days (DAYS_OFFSET+28)
SELECT table_name, partition_name BULK COLLECT INTO STRICT
coll_tables, coll_parts
FROM
(
SELECT table_name, partition_name FROM 
doma_panda.tablepart4copying
WHERE
table_name <> 'FILESTABLE4' 
AND 
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM doma_panda.tablepart4copying WHERE table_name <> 'FILESTABLE4' AND copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND ( date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on) ) >= DAYS_OFFSET


UNION


SELECT table_name, partition_name FROM 
doma_panda.tablepart4copying
WHERE
table_name = 'FILESTABLE4' 
AND 
TRUNC(copying_done_on) =
(
SELECT MIN(TRUNC(copying_done_on)) FROM doma_panda.tablepart4copying WHERE table_name = 'FILESTABLE4' AND copied_to_arch = 'Y' AND coalesce(deleted_on::text, '') = ''
)
AND coalesce(deleted_on::text, '') = ''
AND ( date_trunc('day', clock_timestamp()) - TRUNC(copying_done_on) ) >= (DAYS_OFFSET+28)
) alias21;



-- Verification part --
-- Checks that the PANDAIDs of the partitions that need to be dropped are present (have been copied) to the corresponding ARCH tables
-- check for PANDAID set differences in the JOBSARCHIVED4
IF ( coll_tables.COUNT > 0 AND coll_tables.COUNT = coll_parts.COUNT ) THEN

	FOR j IN 1 .. coll_tables.COUNT LOOP

		IF coll_tables(j) = 'JOBSARCHIVED4' THEN
			jobs_diff := -1;

			-- with FULL table (actually single PARTITION) scan hint
			-- The cardinality hint is needed as sometimes for the partitions in question Oracle stats are missing !!!
			stmt :=	'SELECT /*+ CARDINALITY(tab 500000) index_ffs(tab(PANDAID)) */ COUNT(pandaid)
			from doma_panda.JOBSARCHIVED4 PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT /*+ FULL(subt) CARDINALITY(subt 2000000) */ 1 FROM doma_pandaarch.JOBSARCHIVED subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;


			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);							--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table JOBSARCHIVED4' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'JOBPARAMSTABLE' THEN
			jobs_diff := -1;

			stmt :=	'SELECT
				COUNT(pandaid)
				FROM doma_panda.JOBPARAMSTABLE PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT 1 FROM doma_pandaarch.JOBPARAMSTABLE_ARCH subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;


			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);						--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table JOBPARAMSTABLE' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'METATABLE' THEN
			jobs_diff := -1;

			stmt :=	'SELECT
				COUNT(pandaid)
				FROM doma_panda.METATABLE PARTITION(' || coll_parts(j) || ') tab
			WHERE NOT EXISTS (SELECT 1 FROM doma_pandaarch.METATABLE_ARCH subt
			where PANDAID= tab.PANDAID
			AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)  AND MODIFICATIONTIME <
			TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;

			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);							--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table METATABLE' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;

		IF coll_tables(j) = 'FILESTABLE4' THEN
			jobs_diff := -1;

			stmt:='SELECT
				COUNT(row_id)
				FROM doma_panda.filestable4 PARTITION('|| coll_parts(j) ||') tab
			WHERE NOT EXISTS (SELECT 1 FROM doma_pandaarch.FILESTABLE_ARCH subt
			WHERE ROW_ID = tab.ROW_ID AND MODIFICATIONTIME >= (TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'') - 1)
			AND MODIFICATIONTIME < TO_DATE('''|| SUBSTR(coll_parts(j), -8) ||''', ''DDMMYYYY'')) ';

			EXECUTE stmt INTO STRICT jobs_diff;


			IF (jobs_diff = 0)  THEN
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'YES', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			ELSE
				UPDATE doma_panda.tablepart4copying SET DATA_VERIF_PASSED = 'NO', data_verified_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);							--COMMIT;
				RAISE EXCEPTION '%', 'Not all rows copied from table FILESTABLE4' USING ERRCODE = '45101';
				RETURN;
			END IF;

		END IF;
	END LOOP;
END IF;



-- end of the verification part --
IF ( coll_tables.COUNT > 0 AND coll_tables.COUNT = coll_parts.COUNT ) THEN

	FOR j IN 1 .. coll_tables.COUNT LOOP

		stmt := 'ALTER TABLE '|| coll_tables(j) || ' DROP PARTITION ' || coll_parts(j);

		-- loop until gets exclusive lock on the table
		LOOP
		   BEGIN
			EXECUTE stmt;

			-- add info into the logging table 'tablepart4copying'
			UPDATE doma_panda.tablepart4copying SET deleted_on = clock_timestamp() WHERE table_name = coll_tables(j) AND partition_name = coll_parts(j);
			--COMMIT;
		     	EXIT;
		   EXCEPTION
    			WHEN SQLSTATE '50001' THEN DBMS_LOCK.sleep(1);
		   END;
		END LOOP;

	END LOOP;

	-- the commit is moved within the above loop
	-- --COMMIT;
END IF;

--DBMS_APPLICATION_INFO.SET_MODULE( module_name => null, action_name => null);
--DBMS_APPLICATION_INFO.SET_CLIENT_INFO( client_info => null);

END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE verif_drop_copiedpandapart_v3 (DAYS_OFFSET bigint) owner TO panda;
-- REVOKE ALL ON PROCEDURE doma_panda.verif_drop_copiedpandapart_v3 (DAYS_OFFSET bigint default 2) FROM PUBLIC;

