-- Generated by Ora2Pg, the Oracle database Schema converter, version 21.1
-- Copyright 2000-2020 Gilles DAROLD. All rights reserved.
-- DATASOURCE: dbi:Oracle:INT8R

SET client_encoding TO 'UTF8';

SET search_path = doma_pandabigmon,public;
\set ON_ERROR_STOP ON

SET check_function_bodies = false;



CREATE OR REPLACE PROCEDURE doma_pandabigmon.do_grants (obj_type text, obj_name text,owner_name text) AS $body$
DECLARE

	
	
	privs varchar(100);
BEGIN

	 -- need to put " " around the object names, because some users create the objects with preserved character case.
	IF (obj_name NOT IN ('DO_GRANTS','GRANTS_UPDATE','CREATE_SYN4EXIST_OBJ') AND substr(obj_name,1,4)<>'BIN$' AND substr(obj_name,1,4)<>'SYS_' ) THEN

		IF obj_type IN ('TABLE') THEN
        	 	EXECUTE 'GRANT SELECT,INSERT,UPDATE,DELETE on "'||obj_name||'" to doma_pandabigmon_w';
		        EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_pandabigmon_r';
		elsif obj_type = 'SEQUENCE' THEN
	        	EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_pandabigmon_w';
		        EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_pandabigmon_r';
		elsif obj_type IN ('VIEW', 'MATERIALIZED VIEW') THEN
			privs := ' SELECT,INSERT,UPDATE,DELETE ';
			FOR i IN 1..2 LOOP /*if fails on the first loop with error 01720, then goes to the EXEPTION and changes the statement */
				BEGIN
					EXECUTE 'GRANT '|| privs ||' on "'|| obj_name||'" to doma_pandabigmon_w';
				        EXECUTE 'GRANT SELECT on "'||obj_name||'" to doma_pandabigmon_r';
					EXIT;
				EXCEPTION
					WHEN SQLSTATE '50001' THEN
						privs := ' SELECT ';
				END;
			END LOOP;
		elsif obj_type IN ('PROCEDURE', 'PACKAGE','FUNCTION', 'TYPE') AND obj_name <> 'CREATE_SYN' THEN
	         	EXECUTE 'GRANT EXECUTE on "'||obj_name||'" to doma_pandabigmon_w';
		        EXECUTE 'GRANT EXECUTE on "'||obj_name||'" to doma_pandabigmon_r';
		END IF;
	END IF;
END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE do_grants (obj_type text, obj_name text,owner_name text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_pandabigmon.do_grants (obj_type text, obj_name text,owner_name text) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_pandabigmon.grant_privs4exist_obj (owner_name text ) AS $body$
DECLARE

	
	
	privs varchar(100);
  rec RECORD;
BEGIN
 -- need to put " " around the object names, because some users create the objects with preserved character case.
	-- IMPORTANT - GRANT OBJECT PRIVILEGES FIRST TO THE TABLES
	FOR rec in (SELECT object_name as obj_name, object_type as obj_type FROM all_objects WHERE owner = 'doma_pandabigmon' and object_type = 'table' and substr(object_name,1,4)<>'bin$' and substr(object_name,1,4)<>'sys_') loop
       	 	EXECUTE 'GRANT SELECT,INSERT,UPDATE,DELETE on "'||rec.obj_name||'" to doma_pandabigmon_w';
	        EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_pandabigmon_r';
	END LOOP;

	FOR rec in (SELECT object_name as obj_name, object_type as obj_type FROM all_objects WHERE owner = 'doma_pandabigmon' and object_type in ('view','sequence','procedure', 'package', 'function', 'materialized view', 'type' ) order by object_type desc ) loop

		IF rec.obj_name NOT IN ('DO_GRANTS','GRANTS_UPDATE','GRANT_PRIVS4EXIST_OBJ') THEN
			IF rec.obj_type IN ('VIEW', 'MATERIALIZED VIEW' ) THEN
				privs := ' SELECT,INSERT,UPDATE,DELETE ';
				FOR i IN 1..2 LOOP /*if fails on the first loop with error 01720, then goes to the EXEPTION and changes the statement */
					BEGIN
						EXECUTE 'GRANT '|| privs ||' on "'||rec.obj_name||'" to doma_pandabigmon_w';
					        EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_pandabigmon_r';
						EXIT;
					EXCEPTION
						WHEN SQLSTATE '50001' THEN
						privs := ' SELECT ';
					END;
				END LOOP;
			elsif rec.obj_type = 'SEQUENCE' THEN
	        		EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_pandabigmon_w';
			        EXECUTE 'GRANT SELECT on "'||rec.obj_name||'" to doma_pandabigmon_r';
			elsif rec.obj_type IN ('PROCEDURE', 'PACKAGE','FUNCTION', 'TYPE') AND rec.obj_name <> 'CREATE_SYN' THEN
		         	EXECUTE 'GRANT EXECUTE on "'||rec.obj_name||'" to doma_pandabigmon_w';
			        EXECUTE 'GRANT EXECUTE on "'||rec.obj_name||'" to doma_pandabigmon_r';
			END IF;
		END IF;
	END LOOP;
END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE grant_privs4exist_obj (owner_name text ) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_pandabigmon.grant_privs4exist_obj (owner_name text ) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_pandabigmon.old_query_jobspage_cumulative ( REQUEST_TOKEN bigint, RANGE_DAYS text, WITH_RETRIALS text default 'Y', SHOW_RETRIED_PANDAIDS text default 'N', ATLASRELEASE text default NULL, ATTEMPTNR text default NULL, COMPUTINGSITE text default NULL, CLOUD text default NULL, EVENTSERVICE text default NULL, HOMEPACKAGE text default NULL, INPUTFILEPROJECT text default NULL, INPUTFILETYPE text default NULL, JEDITASKID text default NULL, JOBSTATUS text default NULL, JOBSUBSTATUS text default NULL, MINRAMCOUNT text default NULL, NUCLEUS text default NULL, PROCESSINGTYPE text default NULL, PRODSOURCELABEL text default NULL, PRODUSERNAME text default NULL, REQID text default NULL, TRANSFORMATION text default NULL, WORKINGGROUP text default NULL, BROKERAGEERRORCODE text default NULL, DDMERRORCODE text default NULL, EXEERRORCODE text default NULL, JOBDISPATCHERERRORCODE text default NULL, PILOTERRORCODE text default NULL, SUPERRORCODE text default NULL, TASKBUFFERERRORCODE text default NULL, TRANSEXITCODE text default NULL) AS $body$
DECLARE

-- Necessary in order to avoid "ORA-14551 cannot perform a DML operation inside a query" error
-- PRAGMA AUTONOMOUS_TRANSACTION;
arch_maxtime timestamp;
coll PANDAMON_JOBSPAGE_COLL:= PANDAMON_JOBSPAGE_COLL();
stmt varchar(4000);
my_request_token bigint;
my_range_days bigint;
my_jeditaskid varchar(20);
my_INPUTFILEPROJECT varchar(100);
n_iter bigint:=0;
n_days bigint:=0;
cnt_pandaids bigint:=0;

  j RECORD;

BEGIN


-- Ver 1.2 , 18th Oct 2016
-- In order to validate that the input value is a real number
my_request_token := (REQUEST_TOKEN)::numeric;
my_range_days := (RANGE_DAYS)::numeric;


-- Depends on the asked time window
IF (range_days IS NOT NULL AND range_days::text <> '') THEN

	IF range_days <= 3 THEN

	-- Then call only to the doma_pandabigmon.QUERY_JOBSPAGE is enough
	-- INSERT data from the QUERY_JOBSPAGE function (most recent data )
	------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	 SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 'END' label that the request is done
	INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
	COMMIT;


	ELSE --===============================================================================================================================
	-- The period is larger than the last 3 days and then SUM the result from the QUERY_JOBSPAGE and QUERY_JOBSPAGE_ARCH has to be done
	-- SELECT MAX(modificationtime) into ARCH_MAXTIME from doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH;
	/*
	IMPORTANT: insert into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT table in order to have two independent queries.
	If they are combined in a common SQL call with UNION ALL, then "ORA-08103: object no longer exists" is raised
	often because of the longer execution time on the QUERY_JOBSPAGE_ALL procedure being bound to the query start SCN where the PANDAMON_JOBSPAGE table partition is replaced every 5 minutes
	*/
	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;





	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the given RANGE_DAYS parameter
	----------------------------------------------------------------------------------------------------------------------------------------------------
	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND partition_position >= (SELECT ROUND(MAX(partition_position) - range_days)  FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP

	n_iter :=n_iter+1;

	-- prepare a MERGE instead of INSERT
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;

	END LOOP;



	-- Added on 5th Oct 2016
	-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
	SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

	IF cnt_pandaids <= 100 THEN

		IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

			my_JEDITASKID := JEDITASKID;

			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

		ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN

			my_INPUTFILEPROJECT := INPUTFILEPROJECT;
			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT AND RETRIAL = 'N'  LIMIT 1000;

	-- Unfortunately at that point we do not know the
	--	ELSE
	--	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	--	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where ROWNUM <=1000;
		END IF;

	END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


--============================================================
END IF; -- end of the case when the given RANGE_DAYS is NOT NULL;
ELSE -- the case when the RANGE_DAYS is NULL, then search for the fully available time range when JEDITASK or INPUTFILEPROJECT are given
	IF ( coalesce(JEDITASKID::text, '') = '' and coalesce(INPUTFILEPROJECT::text, '') = '') THEN
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;

	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN
		-- get the full time range of JEDITASKID
		my_JEDITASKID := JEDITASKID;
		SELECT ROUND(clock_timestamp() - TRUNC(MIN(modificationtime))) INTO STRICT n_days FROM doma_pandabigmon.pandamon_jobspage_arch where JEDITASKID = (my_JEDITASKID)::numeric;

	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
		-- get the full time range of INPUTFILEPROJECT
		my_INPUTFILEPROJECT := INPUTFILEPROJECT;
		SELECT ROUND(clock_timestamp() - TRUNC(MIN(modificationtime))) INTO STRICT n_days FROM doma_pandabigmon.pandamon_jobspage_arch where INPUTFILEPROJECT = my_INPUTFILEPROJECT;
	ELSE
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;


	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	-- (hardcoded 30 days because there could be periods of 'stuck' jobs)
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	'30',
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the computed N_DAYS
	----------------------------------------------------------------------------------------------------------------------------------------------------
	 -- BEFORE the loop: Parallelism Settings on session level
	-- EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = TRUE';
	-- EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 6';
	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND partition_position >= (SELECT ROUND(MAX(partition_position) - n_days)  FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP

	n_iter :=n_iter+1;

	-- prepare a MERGE statement for providing a cumulative result
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;


END LOOP;



  -- AFTER the loop: settings on session level
 -- EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = FALSE';
 -- EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 1';
-- Added on 21st Sept 2016
-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

IF cnt_pandaids <= 100 THEN

	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

  RAISE NOTICE ' PANDAIDS list %', my_request_token::varchar;

	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT AND RETRIAL = 'N'  LIMIT 1000;

	END IF;

END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


END IF;


END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE old_query_jobspage_cumulative ( REQUEST_TOKEN bigint, RANGE_DAYS text, WITH_RETRIALS text, SHOW_RETRIED_PANDAIDS text, ATLASRELEASE text, ATTEMPTNR text, COMPUTINGSITE text, CLOUD text, EVENTSERVICE text, HOMEPACKAGE text, INPUTFILEPROJECT text, INPUTFILETYPE text, JEDITASKID text, JOBSTATUS text, JOBSUBSTATUS text, MINRAMCOUNT text, NUCLEUS text, PROCESSINGTYPE text, PRODSOURCELABEL text, PRODUSERNAME text, REQID text, TRANSFORMATION text, WORKINGGROUP text, BROKERAGEERRORCODE text, DDMERRORCODE text, EXEERRORCODE text, JOBDISPATCHERERRORCODE text, PILOTERRORCODE text, SUPERRORCODE text, TASKBUFFERERRORCODE text, TRANSEXITCODE text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_pandabigmon.old_query_jobspage_cumulative ( REQUEST_TOKEN bigint, RANGE_DAYS text, WITH_RETRIALS text default 'Y', SHOW_RETRIED_PANDAIDS text default 'N', ATLASRELEASE text default NULL, ATTEMPTNR text default NULL, COMPUTINGSITE text default NULL, CLOUD text default NULL, EVENTSERVICE text default NULL, HOMEPACKAGE text default NULL, INPUTFILEPROJECT text default NULL, INPUTFILETYPE text default NULL, JEDITASKID text default NULL, JOBSTATUS text default NULL, JOBSUBSTATUS text default NULL, MINRAMCOUNT text default NULL, NUCLEUS text default NULL, PROCESSINGTYPE text default NULL, PRODSOURCELABEL text default NULL, PRODUSERNAME text default NULL, REQID text default NULL, TRANSFORMATION text default NULL, WORKINGGROUP text default NULL, BROKERAGEERRORCODE text default NULL, DDMERRORCODE text default NULL, EXEERRORCODE text default NULL, JOBDISPATCHERERRORCODE text default NULL, PILOTERRORCODE text default NULL, SUPERRORCODE text default NULL, TASKBUFFERERRORCODE text default NULL, TRANSEXITCODE text default NULL) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_pandabigmon.query_jobspage_cumulative ( REQUEST_TOKEN bigint, END_DATE text DEFAULT NULL, RANGE_DAYS text DEFAULT NULL, WITH_RETRIALS text DEFAULT 'Y', SHOW_RETRIED_PANDAIDS text DEFAULT 'N', ATL text DEFAULT NULL) AS $body$
DECLARE
RELEASE text := NULL,
ATTEMPTNR text := NULL,
COMPUTINGSITE text := NULL,
CLOUD text := NULL,
CURRENTPRIORITY text := NULL,
EVENTSERVICE text := NULL,
HOMEPACKAGE text := NULL,
INPUTFILEPROJECT text := NULL,
INPUTFILETYPE text := NULL,
JEDITASKID text := NULL,
JOBSTATUS text := NULL,
JOBSUBSTATUS text := NULL,
MINRAMCOUNT text := NULL,
NUCLEUS text := NULL,
PROCESSINGTYPE text := NULL,
PRODSOURCELABEL text := NULL,
PRODUSERNAME text := NULL,
REQID text := NULL,
TRANSFORMATION text := NULL,
WORKINGGROUP text := NULL,
BROKERAGEERRORCODE text := NULL,
DDMERRORCODE text := NULL,
EXEERRORCODE text := NULL,
JOBDISPATCHERERRORCODE text := NULL,
PILOTERRORCODE text := NULL,
SUPERRORCODE text := NULL,
TASKBUFFERERRORCODE text := NULL,
TRANSEXITCODE text := NULL
)
AS
-- Necessary in order to avoid "ORA-14551 cannot perform a DML operation inside a query" error
-- PRAGMA AUTONOMOUS_TRANSACTION;
arch_maxtime timestamp;
coll PANDAMON_JOBSPAGE_COLL:= PANDAMON_JOBSPAGE_COLL();
stmt varchar(4000);
my_request_token bigint;
my_range_days bigint;
my_jeditaskid varchar(20);
my_INPUTFILEPROJECT varchar(100);
n_iter bigint:=0;
n_days bigint:=0;
cnt_pandaids bigint:=0;

offset_min_partition_pos bigint;
offset_max_partition_pos bigint;

  j RECORD;

BEGIN


-- Ver 1.3, 20th Oct 2016
-- In order to validate that the input value is a real number
my_request_token := (REQUEST_TOKEN)::numeric;
my_range_days := (RANGE_DAYS)::numeric;


-- Several sections depending on the END_DATE and the asked time window backwards in the past
IF (range_days IS NOT NULL AND range_days::text <> '') THEN

	-- IMPORTANT encoded logic: If the END_DATE minus the RANGE_DAYS is larger then the current time minus 3 days, then we fit into the range of most recent 3 days
	-- ========================
	IF ( ((to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') -  (RANGE_DAYS)::numeric ) > (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - 3 ) THEN

	-- Then call only to the doma_pandabigmon.QUERY_JOBSPAGE is enough because the requested time window is within the last 3 days
	-- INSERT data from the QUERY_JOBSPAGE function (most recent data)
	------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	 SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
  :CURRENTPRIORITY,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
  CURRENTPRIORITY,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 'END' label that the request is done
	INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
	COMMIT;


	ELSE --===================================== the period is not only within the last 3 days =============================================================================
	-- =====================================================================================================================================================================
	-- The period is larger than the last 3 days and then SUM the result from the QUERY_JOBSPAGE and QUERY_JOBSPAGE_ARCH has to be done with overlaps of PANDAIDs
	-- SELECT MAX(modificationtime) into ARCH_MAXTIME from doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH;
	/*
	IMPORTANT: insert into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT table in order to have two independent queries.
	If they are combined in a common SQL call with UNION ALL, then "ORA-08103: object no longer exists" is raised
	often because of the longer execution time on the QUERY_JOBSPAGE_ALL procedure being bound to the query start SCN where the PANDAMON_JOBSPAGE table partition is replaced every 5 minutes
	*/
	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
  :CURRENTPRIORITY,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
  CURRENTPRIORITY,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;





	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the given RANGE_DAYS parameter
	----------------------------------------------------------------------------------------------------------------------------------------------------
	-- calculate the time span on in terms of PANDAMON_JOBSPAGE_ARCH table partitions (each partition is a day)
	-- EXTRACT function is used to get the number of days from the calculated interval
	offset_min_partition_pos := TO_NUMBER(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - ( (to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') -  (RANGE_DAYS)::numeric  ) ));

	offset_max_partition_pos := TO_NUMBER(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - ( (to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') ) ));


	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND
	partition_position >= (SELECT ROUND(MAX(partition_position) - offset_min_partition_pos) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	AND
	partition_position <= ( SELECT ROUND(MAX(partition_position) - offset_max_partition_pos) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP

	n_iter :=n_iter+1;

	-- prepare a MERGE instead of INSERT
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
  :CURRENTPRIORITY,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
  CURRENTPRIORITY,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;

	END LOOP;



	-- Added on 5th Oct 2016
	-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
	SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

	IF cnt_pandaids <= 100 THEN

		IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

			my_JEDITASKID := JEDITASKID;

			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

		ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN

			my_INPUTFILEPROJECT := INPUTFILEPROJECT;
			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT  AND RETRIAL = 'N'  LIMIT 1000;

	-- Unfortunately at that point we do not know the
	--	ELSE
	--	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	--	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where ROWNUM <=1000;
		END IF;

	END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


--==================================================================================================
END IF; -- end of the case when the given RANGE_DAYS is NOT NULL;
ELSE -- the case when the RANGE_DAYS is NULL, then search for the fully available time range when JEDITASK or INPUTFILEPROJECT are given
	IF ( coalesce(JEDITASKID::text, '') = '' and coalesce(INPUTFILEPROJECT::text, '') = '') THEN
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;

	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN
		-- get the full time range of JEDITASKID
		my_JEDITASKID := JEDITASKID;
		SELECT ROUND(clock_timestamp() - TRUNC(MIN(modificationtime))) INTO STRICT n_days FROM doma_pandabigmon.pandamon_jobspage_arch where JEDITASKID = (my_JEDITASKID)::numeric;

	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
		-- get the full time range of INPUTFILEPROJECT
		my_INPUTFILEPROJECT := INPUTFILEPROJECT;
		SELECT ROUND(clock_timestamp() - TRUNC(MIN(modificationtime))) INTO STRICT n_days FROM doma_pandabigmon.pandamon_jobspage_arch where INPUTFILEPROJECT = my_INPUTFILEPROJECT;
	ELSE
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;


	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	-- (hardcoded 30 days because there could be periods of 'stuck' jobs)
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
  :CURRENTPRIORITY,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	'30',
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
  CURRENTPRIORITY,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the computed N_DAYS
	----------------------------------------------------------------------------------------------------------------------------------------------------
	 -- BEFORE the loop: Parallelism Settings on session level
	--EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = TRUE';
	--EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 2';
	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND partition_position >= (SELECT ROUND(MAX(partition_position) - n_days)  FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP

	n_iter :=n_iter+1;

	-- prepare a MERGE statement for providing a cumulative result
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
  :CURRENTPRIORITY,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
  CURRENTPRIORITY,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;


END LOOP;


  -- AFTER the loop: settings on session level
  -- EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = FALSE';
  -- EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 1';
-- Added on 21st Sept 2016
-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

IF cnt_pandaids <= 100 THEN

	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT AND RETRIAL = 'N'  LIMIT 1000;

	END IF;

END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


END IF;


END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE query_jobspage_cumulative ( REQUEST_TOKEN bigint, END_DATE text, RANGE_DAYS text, WITH_RETRIALS text, SHOW_RETRIED_PANDAIDS text, ATL text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_pandabigmon.query_jobspage_cumulative ( REQUEST_TOKEN bigint, END_DATE text DEFAULT NULL, RANGE_DAYS text DEFAULT NULL, WITH_RETRIALS text DEFAULT 'Y', SHOW_RETRIED_PANDAIDS text DEFAULT 'N', ATL text DEFAULT NULL) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_pandabigmon.query_jobspage_cumulative_22 ( REQUEST_TOKEN bigint, END_DATE text DEFAULT NULL, RANGE_DAYS text DEFAULT NULL, WITH_RETRIALS text DEFAULT 'Y', SHOW_RETRIED_PANDAIDS text DEFAULT 'N', ATL text DEFAULT NULL) AS $body$
DECLARE
RELEASE text := NULL,
ATTEMPTNR text := NULL,
COMPUTINGSITE text := NULL,
CLOUD text := NULL,
EVENTSERVICE text := NULL,
HOMEPACKAGE text := NULL,
INPUTFILEPROJECT text := NULL,
INPUTFILETYPE text := NULL,
JEDITASKID text := NULL,
JOBSTATUS text := NULL,
JOBSUBSTATUS text := NULL,
MINRAMCOUNT text := NULL,
NUCLEUS text := NULL,
PROCESSINGTYPE text := NULL,
PRODSOURCELABEL text := NULL,
PRODUSERNAME text := NULL,
REQID text := NULL,
TRANSFORMATION text := NULL,
WORKINGGROUP text := NULL,
BROKERAGEERRORCODE text := NULL,
DDMERRORCODE text := NULL,
EXEERRORCODE text := NULL,
JOBDISPATCHERERRORCODE text := NULL,
PILOTERRORCODE text := NULL,
SUPERRORCODE text := NULL,
TASKBUFFERERRORCODE text := NULL,
TRANSEXITCODE text := NULL
)
AS
-- Necessary in order to avoid "ORA-14551 cannot perform a DML operation inside a query" error
-- PRAGMA AUTONOMOUS_TRANSACTION;
arch_maxtime timestamp;
coll PANDAMON_JOBSPAGE_COLL:= PANDAMON_JOBSPAGE_COLL();
stmt varchar(4000);
my_request_token bigint;
my_range_days bigint;
my_jeditaskid varchar(20);
my_INPUTFILEPROJECT varchar(100);
n_iter bigint:=0;
n_days bigint:=0;
cnt_pandaids bigint:=0;

offset_min_partition_pos bigint;
offset_max_partition_pos bigint;
min_modiftime timestamp;
max_modiftime timestamp;

  j RECORD;

BEGIN


-- Ver 1.3, 20th Oct 2016
-- In order to validate that the input value is a real number
my_request_token := (REQUEST_TOKEN)::numeric;
my_range_days := (RANGE_DAYS)::numeric;


-- Several sections depending on the END_DATE and the asked time window backwards in the past
IF (range_days IS NOT NULL AND range_days::text <> '') THEN

	-- IMPORTANT encoded logic: If the END_DATE minus the RANGE_DAYS is larger then the current time minus 3 days, then we fit into the range of most recent 3 days
	-- ========================
	IF ( ((to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') -  (RANGE_DAYS)::numeric ) > (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - 3 ) THEN

	-- Then call only to the doma_pandabigmon.QUERY_JOBSPAGE is enough because the requested time window is within the last 3 days
	-- INSERT data from the QUERY_JOBSPAGE function (most recent data)
	------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	 SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 'END' label that the request is done
	INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
	COMMIT;


	ELSE --===================================== the period is not only within the last 3 days =============================================================================
	-- =====================================================================================================================================================================
	-- The period is larger than the last 3 days and then SUM the result from the QUERY_JOBSPAGE and QUERY_JOBSPAGE_ARCH has to be done with overlaps of PANDAIDs
	-- SELECT MAX(modificationtime) into ARCH_MAXTIME from doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH;
	/*
	IMPORTANT: insert into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT table in order to have two independent queries.
	If they are combined in a common SQL call with UNION ALL, then "ORA-08103: object no longer exists" is raised
	often because of the longer execution time on the QUERY_JOBSPAGE_ALL procedure being bound to the query start SCN where the PANDAMON_JOBSPAGE table partition is replaced every 5 minutes
	*/
	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;





	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the given RANGE_DAYS parameter
	----------------------------------------------------------------------------------------------------------------------------------------------------
	-- calculate the time span on in terms of PANDAMON_JOBSPAGE_ARCH table partitions (each partition is a day)
	-- EXTRACT function is used to get the number of days from the calculated interval
	offset_min_partition_pos := TO_NUMBER(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - ( (to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') -  (RANGE_DAYS)::numeric  ) ));

	offset_max_partition_pos := TO_NUMBER(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - ( (to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') ) ));



	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND
	partition_position >= (SELECT ROUND(MAX(partition_position) - offset_min_partition_pos) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	AND
	partition_position <= ( SELECT ROUND(MAX(partition_position) - offset_max_partition_pos) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP

	n_iter :=n_iter+1;

	-- prepare a MERGE instead of INSERT
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;

	END LOOP;



	-- Added on 5th Oct 2016
	-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
	SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

	IF cnt_pandaids <= 100 THEN

		IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

			my_JEDITASKID := JEDITASKID;

			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

		ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN

			my_INPUTFILEPROJECT := INPUTFILEPROJECT;
			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT  AND RETRIAL = 'N'  LIMIT 1000;

	-- Unfortunately at that point we do not know the
	--	ELSE
	--	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	--	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where ROWNUM <=1000;
		END IF;

	END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


--============================================================
END IF; -- end of the case when the given RANGE_DAYS is NOT NULL;
ELSE -- the case when the RANGE_DAYS is NULL, then search for the fully available time range when JEDITASK or INPUTFILEPROJECT are given
	IF ( coalesce(JEDITASKID::text, '') = '' and coalesce(INPUTFILEPROJECT::text, '') = '') THEN
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;


	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

		-- get the full time range of JEDITASKID
		my_JEDITASKID := JEDITASKID;

		-- Get the timespan of certain JEDITASKID
		SELECT  MIN(modificationtime), MAX(modificationtime) INTO STRICT min_modiftime , max_modiftime
		FROM doma_pandabigmon.pandamon_jobspage_arch where JEDITASKID = (my_JEDITASKID)::numeric;

		SELECT (EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - min_modiftime ) )::numeric  ,
			(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - max_modiftime ) )::numeric
      INTO STRICT  offset_min_partition_pos, offset_max_partition_pos 
		;


	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
		-- get the full time range of INPUTFILEPROJECT
		my_INPUTFILEPROJECT := INPUTFILEPROJECT;
		SELECT ROUND(clock_timestamp() - TRUNC(MIN(modificationtime))) INTO STRICT n_days FROM doma_pandabigmon.pandamon_jobspage_arch where INPUTFILEPROJECT = my_INPUTFILEPROJECT;
	ELSE
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;



/* the old logic 
	IF ( JEDITASKID is NOT NULL) THEN
		-- get the full time range of JEDITASKID
		my_JEDITASKID := JEDITASKID;
		SELECT ROUND(sysdate - TRUNC(MIN(modificationtime))) INTO n_days FROM doma_pandabigmon.pandamon_jobspage_arch where JEDITASKID = to_number(my_JEDITASKID);

	ELSIF ( INPUTFILEPROJECT is NOT NULL) THEN
		-- get the full time range of INPUTFILEPROJECT
		my_INPUTFILEPROJECT := INPUTFILEPROJECT;
		SELECT ROUND(sysdate - TRUNC(MIN(modificationtime))) INTO n_days FROM doma_pandabigmon.pandamon_jobspage_arch where INPUTFILEPROJECT = my_INPUTFILEPROJECT;
	ELSE
		raise_application_error(-20010, 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!');
	END IF;
*/
	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	-- (hardcoded 30 days because there could be periods of 'stuck' jobs)
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	'30',
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the computed N_DAYS
	----------------------------------------------------------------------------------------------------------------------------------------------------
	 -- BEFORE the loop: Parallelism Settings on session level
	--EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = TRUE';
	--EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 2';
	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND
	partition_position >= (SELECT ROUND(MAX(partition_position) - (offset_min_partition_pos +2)) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	AND
	partition_position <= ( SELECT ROUND(MAX(partition_position) - (offset_max_partition_pos-2)) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP


--	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
--	AND partition_position >= (SELECT ROUND(MAX(partition_position) - n_days)  FROM ALL_TAB_PARTITIONS
--	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
--	order by PARTITION_POSITION) LOOP
	n_iter :=n_iter+1;

	-- prepare a MERGE statement for providing a cumulative result
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;


END LOOP;


  -- AFTER the loop: settings on session level
  -- EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = FALSE';
  -- EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 1';
-- Added on 21st Sept 2016
-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

IF cnt_pandaids <= 100 THEN

	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT AND RETRIAL = 'N'  LIMIT 1000;

	END IF;

END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


END IF;


END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE query_jobspage_cumulative_22 ( REQUEST_TOKEN bigint, END_DATE text, RANGE_DAYS text, WITH_RETRIALS text, SHOW_RETRIED_PANDAIDS text, ATL text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_pandabigmon.query_jobspage_cumulative_22 ( REQUEST_TOKEN bigint, END_DATE text DEFAULT NULL, RANGE_DAYS text DEFAULT NULL, WITH_RETRIALS text DEFAULT 'Y', SHOW_RETRIED_PANDAIDS text DEFAULT 'N', ATL text DEFAULT NULL) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_pandabigmon.query_jobspage_cumulative_mm ( REQUEST_TOKEN bigint, END_DATE text DEFAULT NULL, RANGE_DAYS text DEFAULT NULL, WITH_RETRIALS text DEFAULT 'Y', SHOW_RETRIED_PANDAIDS text DEFAULT 'N', ATL text DEFAULT NULL) AS $body$
DECLARE
RELEASE text := NULL,
ATTEMPTNR text := NULL,
COMPUTINGSITE text := NULL,
CLOUD text := NULL,
EVENTSERVICE text := NULL,
HOMEPACKAGE text := NULL,
INPUTFILEPROJECT text := NULL,
INPUTFILETYPE text := NULL,
JEDITASKID text := NULL,
JOBSTATUS text := NULL,
JOBSUBSTATUS text := NULL,
MINRAMCOUNT text := NULL,
NUCLEUS text := NULL,
PROCESSINGTYPE text := NULL,
PRODSOURCELABEL text := NULL,
PRODUSERNAME text := NULL,
REQID text := NULL,
TRANSFORMATION text := NULL,
WORKINGGROUP text := NULL,
BROKERAGEERRORCODE text := NULL,
DDMERRORCODE text := NULL,
EXEERRORCODE text := NULL,
JOBDISPATCHERERRORCODE text := NULL,
PILOTERRORCODE text := NULL,
SUPERRORCODE text := NULL,
TASKBUFFERERRORCODE text := NULL,
TRANSEXITCODE text := NULL
)
AS
-- Necessary in order to avoid "ORA-14551 cannot perform a DML operation inside a query" error
-- PRAGMA AUTONOMOUS_TRANSACTION;
arch_maxtime timestamp;
coll PANDAMON_JOBSPAGE_COLL:= PANDAMON_JOBSPAGE_COLL();
stmt varchar(4000);
my_request_token bigint;
my_range_days bigint;
my_jeditaskid varchar(20);
my_INPUTFILEPROJECT varchar(100);
n_iter bigint:=0;
n_days bigint:=0;
cnt_pandaids bigint:=0;

offset_min_partition_pos bigint;
offset_max_partition_pos bigint;
min_modiftime timestamp;
max_modiftime timestamp;

  j RECORD;

BEGIN


-- Ver 1.3, 20th Oct 2016
-- In order to validate that the input value is a real number
my_request_token := (REQUEST_TOKEN)::numeric;
my_range_days := (RANGE_DAYS)::numeric;


-- Several sections depending on the END_DATE and the asked time window backwards in the past
IF (range_days IS NOT NULL AND range_days::text <> '') THEN

	-- IMPORTANT encoded logic: If the END_DATE minus the RANGE_DAYS is larger then the current time minus 3 days, then we fit into the range of most recent 3 days
	-- ========================
	IF ( ((to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') -  (RANGE_DAYS)::numeric ) > (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - 3 ) THEN

	-- Then call only to the doma_pandabigmon.QUERY_JOBSPAGE is enough because the requested time window is within the last 3 days
	-- INSERT data from the QUERY_JOBSPAGE function (most recent data)
	------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	 SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 'END' label that the request is done
	INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
	COMMIT;


	ELSE --===================================== the period is not only within the last 3 days =============================================================================
	-- =====================================================================================================================================================================
	-- The period is larger than the last 3 days and then SUM the result from the QUERY_JOBSPAGE and QUERY_JOBSPAGE_ARCH has to be done with overlaps of PANDAIDs
	-- SELECT MAX(modificationtime) into ARCH_MAXTIME from doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH;
	/*
	IMPORTANT: insert into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT table in order to have two independent queries.
	If they are combined in a common SQL call with UNION ALL, then "ORA-08103: object no longer exists" is raised
	often because of the longer execution time on the QUERY_JOBSPAGE_ALL procedure being bound to the query start SCN where the PANDAMON_JOBSPAGE table partition is replaced every 5 minutes
	*/
	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	RANGE_DAYS,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;





	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the given RANGE_DAYS parameter
	----------------------------------------------------------------------------------------------------------------------------------------------------
	-- calculate the time span on in terms of PANDAMON_JOBSPAGE_ARCH table partitions (each partition is a day)
	-- EXTRACT function is used to get the number of days from the calculated interval
	offset_min_partition_pos := TO_NUMBER(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - ( (to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') -  (RANGE_DAYS)::numeric  ) ));

	offset_max_partition_pos := TO_NUMBER(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - ( (to_timestamp(END_DATE, 'DD-MM-YYYY HH24:MI:SS.US:') AT TIME ZONE 'UTC') ) ));



	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND
	partition_position >= (SELECT ROUND(MAX(partition_position) - offset_min_partition_pos) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	AND
	partition_position <= ( SELECT ROUND(MAX(partition_position) - offset_max_partition_pos) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP

	n_iter :=n_iter+1;

	-- prepare a MERGE instead of INSERT
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;

	END LOOP;



	-- Added on 5th Oct 2016
	-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
	SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

	IF cnt_pandaids <= 100 THEN

		IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

			my_JEDITASKID := JEDITASKID;

			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

		ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN

			my_INPUTFILEPROJECT := INPUTFILEPROJECT;
			INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
			SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT  AND RETRIAL = 'N'  LIMIT 1000;

	-- Unfortunately at that point we do not know the
	--	ELSE
	--	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	--	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where ROWNUM <=1000;
		END IF;

	END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


--============================================================
END IF; -- end of the case when the given RANGE_DAYS is NOT NULL;
ELSE -- the case when the RANGE_DAYS is NULL, then search for the fully available time range when JEDITASK or INPUTFILEPROJECT are given
	IF ( coalesce(JEDITASKID::text, '') = '' and coalesce(INPUTFILEPROJECT::text, '') = '') THEN
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;


	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

		-- get the full time range of JEDITASKID
		my_JEDITASKID := JEDITASKID;

		-- Get the timespan of certain JEDITASKID
		SELECT  MIN(modificationtime), MAX(modificationtime) INTO STRICT min_modiftime , max_modiftime
		FROM doma_pandabigmon.pandamon_jobspage_arch where JEDITASKID = (my_JEDITASKID)::numeric;

		SELECT (EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - min_modiftime ) )::numeric  ,
			(EXTRACT( DAY FROM (CURRENT_TIMESTAMP AT TIME ZONE 'UTC') - max_modiftime ) )::numeric
      INTO STRICT  offset_min_partition_pos, offset_max_partition_pos 
		;


	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
		-- get the full time range of INPUTFILEPROJECT
		my_INPUTFILEPROJECT := INPUTFILEPROJECT;
		SELECT ROUND(clock_timestamp() - TRUNC(MIN(modificationtime))) INTO STRICT n_days FROM doma_pandabigmon.pandamon_jobspage_arch where INPUTFILEPROJECT = my_INPUTFILEPROJECT;
	ELSE
		RAISE EXCEPTION '%', 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!' USING ERRCODE = '45010';
	END IF;



/* the old logic 
	IF ( JEDITASKID is NOT NULL) THEN
		-- get the full time range of JEDITASKID
		my_JEDITASKID := JEDITASKID;
		SELECT ROUND(sysdate - TRUNC(MIN(modificationtime))) INTO n_days FROM doma_pandabigmon.pandamon_jobspage_arch where JEDITASKID = to_number(my_JEDITASKID);

	ELSIF ( INPUTFILEPROJECT is NOT NULL) THEN
		-- get the full time range of INPUTFILEPROJECT
		my_INPUTFILEPROJECT := INPUTFILEPROJECT;
		SELECT ROUND(sysdate - TRUNC(MIN(modificationtime))) INTO n_days FROM doma_pandabigmon.pandamon_jobspage_arch where INPUTFILEPROJECT = my_INPUTFILEPROJECT;
	ELSE
		raise_application_error(-20010, 'Undefined time window is available only for JEDITASKID or INPUTFILEPROJECT job attributes!');
	END IF;
*/
	-- 1.1: Call to the doma_pandabigmon.QUERY_JOBSPAGE to insert aggregated data of the most recent PanDA data
	-- (hardcoded 30 days because there could be periods of 'stuck' jobs)
	--------------------------------------------------------------------------------------------------------------
	stmt:= 'INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
 	SELECT :request_token, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES, :n_iter FROM table
	(
	doma_pandabigmon.QUERY_JOBSPAGE
	(
	:END_DATE,
	:RANGE_DAYS,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE
	)
	) ';

	n_iter := n_iter+1;

	EXECUTE stmt USING
	my_request_token,
	n_iter,
	END_DATE,
	'30',
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE;


	-- 1.2: MERGE data into the JOBSPAGE_CUMULATIVE_RESULT partition by partition by calling the QUERY_JOBSPAGE_ARCH_PARTITION function in a loop
	-- Get all partitions by position > the partition number - the computed N_DAYS
	----------------------------------------------------------------------------------------------------------------------------------------------------
	 -- BEFORE the loop: Parallelism Settings on session level
	--EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = TRUE';
	--EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 2';
	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
	AND
	partition_position >= (SELECT ROUND(MAX(partition_position) - (offset_min_partition_pos +2)) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	AND
	partition_position <= ( SELECT ROUND(MAX(partition_position) - (offset_max_partition_pos-2)) FROM ALL_TAB_PARTITIONS
	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
	order by PARTITION_POSITION) LOOP


--	FOR j IN (SELECT partition_name  FROM ALL_TAB_PARTITIONS WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch'
--	AND partition_position >= (SELECT ROUND(MAX(partition_position) - n_days)  FROM ALL_TAB_PARTITIONS
--	WHERE table_owner = 'doma_pandabigmon' and table_name = 'pandamon_jobspage_arch' )
--	order by PARTITION_POSITION) LOOP
	n_iter :=n_iter+1;

	-- prepare a MERGE statement for providing a cumulative result
	stmt:= 'MERGE into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT aggr
	USING
	(
	SELECT '|| my_request_token::varchar ||' as MY_REQ_TOKEN, PANDA_ATTRIBUTE, ATTR_VALUE, NUM_OCCURRENCES
	FROM table(doma_pandabigmon.QUERY_JOBSPAGE_ARCH_PARTITION
	(:PARTITION_NAME,
	:WITH_RETRIALS,
	:SHOW_RETRIED_PANDAIDS,
	:ATLASRELEASE,
	:ATTEMPTNR,
	:COMPUTINGSITE,
	:CLOUD,
	:EVENTSERVICE,
	:HOMEPACKAGE,
	:INPUTFILEPROJECT,
	:INPUTFILETYPE,
	:JEDITASKID,
	:JOBSTATUS,
	:JOBSUBSTATUS,
	:MINRAMCOUNT,
	:NUCLEUS,
	:PROCESSINGTYPE,
	:PRODSOURCELABEL ,
	:PRODUSERNAME ,
	:REQID ,
	:TRANSFORMATION ,
	:WORKINGGROUP ,
	:BROKERAGEERRORCODE ,
	:DDMERRORCODE ,
	:EXEERRORCODE ,
	:JOBDISPATCHERERRORCODE ,
	:PILOTERRORCODE ,
	:SUPERRORCODE ,
	:TASKBUFFERERRORCODE ,
	:TRANSEXITCODE)
	)) part
	ON (aggr.REQUEST_TOKEN = part.MY_REQ_TOKEN AND aggr.ATTR=part.PANDA_ATTRIBUTE AND aggr.ATTR_VALUE=part.ATTR_VALUE )
	WHEN MATCHED THEN
	UPDATE SET aggr.NUM_OCCUR = aggr.NUM_OCCUR + part.NUM_OCCURRENCES, aggr.NUM_ITERATIONS = aggr.NUM_ITERATIONS+1
	WHEN NOT MATCHED THEN
	INSERT (REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS)
	VALUES (part.MY_REQ_TOKEN, part.PANDA_ATTRIBUTE, part.ATTR_VALUE, part.NUM_OCCURRENCES, :n_iter ) ';


	--DBMS_OUTPUT.put_line(stmt);
	EXECUTE stmt USING
	j.partition_name,
	WITH_RETRIALS,
	SHOW_RETRIED_PANDAIDS,
	ATLASRELEASE,
	ATTEMPTNR,
	COMPUTINGSITE,
	CLOUD,
	EVENTSERVICE,
	HOMEPACKAGE,
	INPUTFILEPROJECT,
	INPUTFILETYPE,
	JEDITASKID,
	JOBSTATUS,
	JOBSUBSTATUS,
	MINRAMCOUNT,
	NUCLEUS,
	PROCESSINGTYPE,
	PRODSOURCELABEL ,
	PRODUSERNAME ,
	REQID ,
	TRANSFORMATION ,
	WORKINGGROUP ,
	BROKERAGEERRORCODE ,
	DDMERRORCODE ,
	EXEERRORCODE ,
	JOBDISPATCHERERRORCODE ,
	PILOTERRORCODE ,
	SUPERRORCODE ,
	TASKBUFFERERRORCODE ,
	TRANSEXITCODE,
	n_iter;


	-- commit the intermediate result
	COMMIT;


END LOOP;


  -- AFTER the loop: settings on session level
  -- EXECUTE IMMEDIATE 'ALTER SESSION SET PARALLEL_FORCE_LOCAL = FALSE';
  -- EXECUTE IMMEDIATE 'ALTER SESSION FORCE PARALLEL QUERY parallel 1';
-- Added on 21st Sept 2016
-- If the number of PanDAIDs is less than 100 then get the first found 1000 PANDAIDs from the PANDAMON_JOBSPAGE_ARCH table
SELECT count(*) INTO STRICT cnt_pandaids from doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT where REQUEST_TOKEN = my_request_token and attr = 'PANDAID';

IF cnt_pandaids <= 100 THEN

	IF (JEDITASKID IS NOT NULL AND JEDITASKID::text <> '') THEN

	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where JEDITASKID = my_JEDITASKID AND RETRIAL = 'N'  LIMIT 1000;

	ELSIF (INPUTFILEPROJECT IS NOT NULL AND INPUTFILEPROJECT::text <> '') THEN
	INSERT INTO doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS )
	SELECT my_request_token , 'PANDAID', pandaid, 1, 1 FROM doma_pandabigmon.PANDAMON_JOBSPAGE_ARCH where INPUTFILEPROJECT = my_INPUTFILEPROJECT AND RETRIAL = 'N'  LIMIT 1000;

	END IF;

END IF;


-- 'END' label that the request is done
INSERT into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT(REQUEST_TOKEN, ATTR, ATTR_VALUE, NUM_OCCUR, NUM_ITERATIONS ) VALUES (my_request_token, 'END', 'END', 1 , n_iter );
COMMIT;


END IF;


END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE query_jobspage_cumulative_mm ( REQUEST_TOKEN bigint, END_DATE text, RANGE_DAYS text, WITH_RETRIALS text, SHOW_RETRIED_PANDAIDS text, ATL text) OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_pandabigmon.query_jobspage_cumulative_mm ( REQUEST_TOKEN bigint, END_DATE text DEFAULT NULL, RANGE_DAYS text DEFAULT NULL, WITH_RETRIALS text DEFAULT 'Y', SHOW_RETRIED_PANDAIDS text DEFAULT 'N', ATL text DEFAULT NULL) FROM PUBLIC;



CREATE OR REPLACE PROCEDURE doma_pandabigmon.test_aggr_proc () AS $body$
DECLARE

  -- the cursor
  
  jobs_cursor REFCURSOR;

  -- objects to store the data fetched by the cursor
  TYPE jobs_attr_coll IS TABLE OF jobs_attr_rec;
  jobs_coll jobs_attr_coll;

  -- the mappers, example: attr_name: ATLASRELEASE,
  --                       job_map:   Atlas-17.2.11, 
  --                                  1730
  TYPE mapper IS TABLE OF bigint INDEX BY varchar(200);
  TYPE t_attr_tab is table of attr_rec index by integer;
  attr_tab t_attr_tab;

  l_idx varchar(100);
  sql_stmt varchar(1000);

BEGIN
  sql_stmt := 'select ATLASRELEASE, ATTEMPTNR, COMPUTINGSITE, 
                      CLOUD, EVENTSERVICE, HOMEPACKAGE, INPUTFILEPROJECT,
                      INPUTFILETYPE, JEDITASKID, JOBSTATUS
              from doma_pandabigmon.PANDAMON_JOBSPAGE
              WHERE MODIFICATIONTIME > SYS_EXTRACT_UTC(TO_TIMESTAMP_TZ(''25-10-2016 15:09:10.254236000 +02:00'', ''DD-MM-YYYY HH24:MI:SS.FF TZH:TZM'') ) - 1 
              AND MODIFICATIONTIME <= SYS_EXTRACT_UTC(TO_TIMESTAMP_TZ(''25-10-2016 15:09:10.254236000 +02:00'', ''DD-MM-YYYY HH24:MI:SS.FF TZH:TZM'') )
              ORDER BY ATLASRELEASE';

  OPEN jobs_cursor FOR EXECUTE sql_stmt;
  loop
    FETCH jobs_cursor BULK COLLECT INTO jobs_coll LIMIT 5000;
    for i IN 1 .. jobs_coll.count
    loop
    begin
      --dbms_output.put_line('----------------------------------------------');
      --dbms_output.put_line('ATLASRELEASE  |  ATTEMPTNR |  COMPUTINGSITE');
      --dbms_output.put_line('----------------------------------------------');
      --dbms_output.put_line(jobs_coll(i).ATLASRELEASE|| ' |      '||jobs_coll(i).ATTEMPTNR||'    | '||jobs_coll(i).COMPUTINGSITE);
      if jobs_coll[i](.ATLASRELEASE IS NOT NULL AND .ATLASRELEASE::text <> '')
        THEN
        attr_tab[1].attr_name := 'ATLASRELEASE';

        if (attr_tab[1].job_map.exists(jobs_coll[i].ATLASRELEASE))
        then 
          attr_tab[1].job_map(jobs_coll[i].ATLASRELEASE) := attr_tab[1].job_map(jobs_coll[i].ATLASRELEASE) + 1;
          --dbms_output.put_line('1 increment by 1 >>>> ' ||  attr_tab(1).job_map(jobs_coll(i).ATLASRELEASE));
        else
          attr_tab[1].job_map(jobs_coll[i].ATLASRELEASE) := 1;
          --dbms_output.put_line('1 starts with 1 >>>>' ||  attr_tab(1).job_map(jobs_coll(i).ATLASRELEASE));
        end if;
        --dbms_output.put_line('THE KEY FOR ATLASRELEASE IS ===========> ' ||  jobs_coll(i).ATLASRELEASE || ' NEW VALUE IS ' ||  attr_tab(1).job_map(jobs_coll(i).ATLASRELEASE));
      end if;

     if (jobs_coll[i](.ATTEMPTNR IS NOT NULL AND .ATTEMPTNR::text <> ''))
      THEN
        attr_tab[2].attr_name := 'ATTEMPTNR';
        if (attr_tab[2].job_map.exists(jobs_coll[i].ATTEMPTNR))
        then
          --dbms_output.put_line('2 increment by 1 >>>> ' ||  attr_tab(2).job_map(jobs_coll(i).ATTEMPTNR));
          attr_tab[2].job_map(jobs_coll[i].ATTEMPTNR) := attr_tab[2].job_map(jobs_coll[i].ATTEMPTNR) + 1;
        else

          attr_tab[2].job_map(jobs_coll[i].ATTEMPTNR) := 1;
          --dbms_output.put_line('2 starts with 1 >>>>' ||  attr_tab(2).job_map(jobs_coll(i).ATTEMPTNR));
        end if;
        --dbms_output.put_line('THE KEY FOR ATTEMPTNR IS ===========> ' ||  jobs_coll(i).ATTEMPTNR || ' NEW VALUE IS ' ||  attr_tab(2).job_map(jobs_coll(i).ATTEMPTNR));
      end if;

      
      if (jobs_coll[i](.COMPUTINGSITE IS NOT NULL AND .COMPUTINGSITE::text <> ''))
      THEN
        attr_tab[3].attr_name := 'COMPUTINGSITE';
        if (attr_tab[3].job_map.exists(jobs_coll[i].COMPUTINGSITE))
        then
          attr_tab[3].job_map(jobs_coll[i].COMPUTINGSITE) := attr_tab[3].job_map(jobs_coll[i].COMPUTINGSITE) + 1;
        else
          attr_tab[3].job_map(jobs_coll[i].COMPUTINGSITE) := 1;
        end if;
      end if;


            
     
    
      
      EXCEPTION
        WHEN no_data_found THEN
          NULL;
      END;

      
    end loop;

  EXIT WHEN NOT FOUND; /* apply on jobs_cursor */
  END LOOP;
  CLOSE jobs_cursor;

  /*for n in 1..attr_tab.count loop
    --dbms_output.put_line('attr_name: '||attr_tab(n).attr_name);
    l_idx := attr_tab(n).job_map.first;
     while (l_idx is not null) loop
        --dbms_output.put_line(attr_tab(n).attr_name||'  Key = ' || l_idx || ' :Value = ' || attr_tab(n).job_map(l_idx));
        --insert into doma_pandabigmon.JOBSPAGE_CUMULATIVE_RESULT values (1000, attr_tab(n).attr_name, l_idx, attr_tab(n).job_map(l_idx), 1, sysdate);
        --commit;
        l_idx := attr_tab(n).job_map.next(l_idx);
     end loop;
    --dbms_output.put_line('attr_name: '||attr_tab(n).job_map);
    
  end loop; */
END;
$body$
LANGUAGE PLPGSQL
;
ALTER PROCEDURE test_aggr_proc () OWNER TO panda;
-- REVOKE ALL ON PROCEDURE doma_pandabigmon.test_aggr_proc () FROM PUBLIC;

